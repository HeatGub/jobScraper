{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a browser and set the cookies from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "\n",
    "def setCookiesFromJson():\n",
    "    with open('cookies.json', 'r', newline='') as inputdata:\n",
    "        cookies = json.load(inputdata)\n",
    "    for cookie in cookies: #works only after driver.get\n",
    "        driver.add_cookie(cookie)\n",
    "    driver.refresh() # to load cookies\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# base_url = \"https://theprotocol.it/filtry/python;t/ai-ml;sp\"\n",
    "# base_url = \"https://theprotocol.it/filtry/python;t/ai-ml;sp/bialystok;wp\"\n",
    "# base_url = \"https://theprotocol.it/filtry/sql,python,javascript;t/junior,trainee,assistant;p\"\n",
    "# base_url = \"https://theprotocol.it/filtry/helpdesk;sp/warszawa,bialystok;wp/zdalna,hybrydowa,stacjonarna;rw/\"\n",
    "base_url = \"https://theprotocol.it/filtry/trainee,assistant,junior;p\"\n",
    "driver.get(base_url)\n",
    "setCookiesFromJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the URLs from all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 urls fetched\n",
      "page 2 urls fetched\n",
      "page 3 urls fetched\n",
      "page 4 urls fetched\n",
      "page 5 urls fetched\n",
      "page 6 urls fetched\n",
      "page 7 urls fetched\n",
      "page 8 urls fetched\n",
      "fetched 355 offer urls in total\n"
     ]
    }
   ],
   "source": [
    "def anyOffersOnTheList():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '#main-offers-listing > div.hfenof > div.t2re51w > div')\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "offers_urls = []\n",
    "\n",
    "def fetchOffersUrlsFromSinglePage():\n",
    "    offersContainer = driver.find_element(\"xpath\", '//*[@id=\"main-offers-listing\"]/div[1]/div')\n",
    "    offers = offersContainer.find_elements(By.CLASS_NAME, 'a4pzt2q ')\n",
    "    # offers = offersContainer.find_elements(By.CSS_SELECTOR, '#offer-title') #also works\n",
    "    # print('\\t'+ str(len(offers)) + ' offers:')\n",
    "    for offer in offers:\n",
    "        offers_urls.append(offer.get_property(\"href\"))\n",
    "\n",
    "page = 1 #theprotocol enumerates pages starting from 1\n",
    "while True: # because not sure how many pages are there\n",
    "    site = driver.get(base_url + \"?pageNumber=\" + str(page))\n",
    "    if not anyOffersOnTheList():\n",
    "        print('fetched ' + str(len(offers_urls)) + ' offer urls in total')\n",
    "        break # break if no results\n",
    "    else:\n",
    "        time.sleep(random.uniform(0.5, 1)) #humanize\n",
    "        fetchOffersUrlsFromSinglePage()\n",
    "        print('page ' + str(page) + ' urls fetched')\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse offer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offerNotFound():\n",
    "    try:\n",
    "        driver.find_element(\"xpath\", '//*[@data-test=\"text-offerNotFound\"]')\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def getOfferDetails():\n",
    "    #JOB TITLE\n",
    "    try:\n",
    "        jobTitle = driver.find_element(By.XPATH, '//*[@data-test=\"text-offerTitle\"]') # this element should always exist\n",
    "        jobTitle = jobTitle.text\n",
    "    except:\n",
    "        jobTitle = None\n",
    "    \n",
    "    #SALARY\n",
    "    try:\n",
    "        salaryContainer = driver.find_element(By.XPATH, '//*[@data-test=\"section-contract\"]') # this element should always exist\n",
    "        salaryAndContract = salaryContainer.text\n",
    "        # print(salaryAndContract  + '\\n')\n",
    "    except:\n",
    "        salaryAndContract = None\n",
    "    \n",
    "    salaryMinAndMax = [None, None]\n",
    "    if salaryAndContract:\n",
    "        try: #to recalculate salary to [PLN/month net] #PLN=only unit on protocol?\n",
    "            grossToNetMultiplier = 0.7\n",
    "            hoursPerMonthInFullTimeJob = 168\n",
    "            lines = salaryAndContract.splitlines()\n",
    "            if len(lines) >= 3: #should be 2-3 tho\n",
    "                lines[0] = lines[0].replace(\" \", \"\") #remove spaces\n",
    "                lines[0] = re.sub(r\",\\d{1,2}\", '', lines[0]) #removes dash and /d x(1-2)  (needed when salary as 123,45)\n",
    "                salaryMinAndMax = re.findall(r\"\\d+\", lines[0]) #r = raw\n",
    "                # print(salaryMinAndMax.split(',', 1)[0])\n",
    "                # salaryUnit = re.findall(r\"[^\\d–-]\", lines[0]) #[exclude digits and –/-]\n",
    "                # salaryUnit = ''.join(salaryUnit) #join list elements\n",
    "                if re.findall(\"brutto\", lines[1]) or re.findall(\"gross\", lines[1]): # gross -> net\n",
    "                    salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "                    # print(salaryMinAndMax)\n",
    "                if re.findall(\"godz\", lines[1]) or re.findall(\"hr.\", lines[1]): # hr -> month\n",
    "                    salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str\n",
    "\n",
    "                salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "        except:\n",
    "            pass    # salaryMinAndMax = [None, None]\n",
    "\n",
    "    # EMPLOYER\n",
    "    try:\n",
    "        employerElement = driver.find_element(\"xpath\", '//*[@data-test=\"anchor-company-link\"]') # this element should always exist\n",
    "        employer = employerElement.text + ' ' + employerElement.get_property(\"href\")\n",
    "    except:\n",
    "        employer = None\n",
    "    # print(employer  + '\\n')\n",
    "    \n",
    "    #WORKFROM, EXP, VALIDTO, LOCATION - \"PARAMETERS\"\n",
    "    workModes, positionLevels, offerValidTo, location = '', '', '', ''\n",
    "    parametersContainer = driver.find_element(By.CLASS_NAME, \"c21kfgf\")\n",
    "    parameters = parametersContainer.find_elements(By.CLASS_NAME, \"s1bu9jax\")\n",
    "    for param in parameters:\n",
    "        paramType = param.get_attribute(\"data-test\") #element description\n",
    "        match paramType:\n",
    "            case \"section-workModes\":\n",
    "                workModes = param.text\n",
    "            case \"section-positionLevels\":\n",
    "                positionLevels = param.text\n",
    "            case \"section-offerValidTo\":\n",
    "                offerValidTo = param.text\n",
    "            case \"section-workplace\":\n",
    "                location = param.text\n",
    "                try: #to find and click 'more locations' button then fetch what's inside\n",
    "                    moreLocations = driver.find_element(\"xpath\", '//*[@data-test=\"button-locationPicker\"]')\n",
    "                    moreLocations.click()\n",
    "                    # time.sleep(0.05) #probably necessary\n",
    "                    locations = moreLocations.find_element(\"xpath\", '//*[@data-test=\"modal-locations\"]')\n",
    "                    location = locations.text\n",
    "                except:\n",
    "                    pass #leave location as it was\n",
    "    # print(workModes + '\\n\\n' + positionLevels + '\\n\\n' +  offerValidTo + '\\n\\n' +  location + '\\n')\n",
    "\n",
    "    # # # TECHSTACK\n",
    "    descriptionsContainer = driver.find_element(By.CSS_SELECTOR, '#TECHNOLOGY_AND_POSITION')\n",
    "\n",
    "    techstack = descriptionsContainer.find_elements(By.CLASS_NAME, \"c1fj2x2p\")\n",
    "    techstackExpected = None\n",
    "    techstackOptional = None\n",
    "    for group in techstack:\n",
    "        if group.text[0:8] == 'EXPECTED' or group.text[0:8] == 'WYMAGANE':\n",
    "            techstackExpected = group.text[9:]\n",
    "        elif group.text[0:8] == 'OPTIONAL': #never saw polish version yet\n",
    "            techstackOptional = group.text[9:]\n",
    "    # print(techstackExpected + '\\n\\n' + techstackOptional + '\\n')\n",
    "\n",
    "    #RESPONSIBILITIES\n",
    "    try:\n",
    "        try:\n",
    "            responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]/ul').text #/only ul elements\n",
    "        except:\n",
    "            responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]').text #/if it's a single entry\n",
    "    except:\n",
    "        responsibilities = None\n",
    "        # print('RESPONSIBILITIES:\\n' + str(responsibilities) + '\\n' + driver.current_url)\n",
    "\n",
    "    #REQUIREMENTS\n",
    "    try:\n",
    "        try:\n",
    "            requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]/ul').text\n",
    "        except:\n",
    "            requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]').text #/if it's a single entry\n",
    "    except:\n",
    "        requirements = None\n",
    "        # print('REQUIREMENTS:\\n' + str(requirements) + '\\n' + driver.current_url)\n",
    "\n",
    "\n",
    "    #OPTIONAL REQUIREMENTS\n",
    "    try:\n",
    "        optionalRequirementsContainer = descriptionsContainer.find_elements(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]/li')\n",
    "        if len(optionalRequirementsContainer) > 0:\n",
    "            optionalRequirements = ''\n",
    "            for optionalRequirement in optionalRequirementsContainer:\n",
    "                optionalRequirements += optionalRequirement.text + '\\n'\n",
    "        elif len(optionalRequirementsContainer) <= 0:\n",
    "            try:\n",
    "                optionalRequirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]').text\n",
    "            except:\n",
    "                optionalRequirements = None\n",
    "                # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)        \n",
    "    except:\n",
    "        optionalRequirements = None\n",
    "    # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)\n",
    "    datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return [datetimeNow, datetimeNow, driver.current_url, jobTitle, salaryAndContract, salaryMinAndMax[0], salaryMinAndMax[1], employer, workModes, positionLevels, offerValidTo, location, techstackExpected, techstackOptional, responsibilities, requirements, optionalRequirements]\n",
    "\n",
    "# driver.get('https://theprotocol.it/szczegoly/praca/informatyk-zamosc-strefowa-10,oferta,cd300000-23ab-a26d-445c-08dce14a2562?s=8321028996&searchId=243e7f60-84d9-11ef-8246-7b66699012e8')\n",
    "# getOfferDetails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'207'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(resultsDataFrame.employer)\n",
    "# # resultsDataFrame.to_sql('offers', 'resultsDf.db') #alchemy needed\n",
    "import sqlite3\n",
    "\n",
    "tableName = 'test4' #not needed as an argument\n",
    "\n",
    "class database():\n",
    "    def createTableIfNotExists(): #if not exists\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS \" + tableName + \"\"\" (\n",
    "                    datetimeFirst TEXT,\n",
    "                    datetimeLast TEXT,\n",
    "                    url TEXT,\n",
    "                    title TEXT, \n",
    "                    salaryAndContract TEXT,\n",
    "                    salaryMin INT,\n",
    "                    salaryMax INT,\n",
    "                    employer TEXT,\n",
    "                    workModes TEXT,\n",
    "                    positionLevels TEXT,\n",
    "                    offerValidTo TEXT,\n",
    "                    location TEXT,\n",
    "                    techstackExpected TEXT,\n",
    "                    techstackOptional TEXT,\n",
    "                    responsibilities TEXT,\n",
    "                    requirements TEXT,\n",
    "                    optionalRequirements TEXT);\"\"\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def selectAll():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM\" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def executeQuery(query):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def recordFound(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        # print(urlPartToCompare)\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT datetimeFirst FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if len(result) >0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def insertRecord(dictionary):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"INSERT INTO \" + tableName + \" VALUES (:datetimeFirst, :datetimeLast, :url, :title, :salaryAndContract, :salaryMin, :salaryMax, :employer, :workModes, :positionLevels, :offerValidTo, :location, :techstackExpected, :techstackOptional, :responsibilities, :requirements, :optionalRequirements)\", dictionary)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def updateDatetimeLast(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"UPDATE \" + tableName + \" SET datetimeLast = '\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")) + \"'  WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        # cursor.execute(\"SELECT datetimeLast FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def countAllRecords():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT COUNT (*) FROM \" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        resultTuple = cursor.fetchall()[0]\n",
    "        (count,) = resultTuple #unpacking tuple\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return str(count)\n",
    "\n",
    "    def queryToDataframe(fullQuery):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        # df = pd.read_sql(\"SELECT datetimeFirst, datetimeLast FROM \" +tableName+ \";\", con=connection)\n",
    "        df = pd.read_sql(fullQuery, con=connection)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        # print('\\n'+str(len(cursor.fetchall())) + ' records found')\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return df\n",
    "    \n",
    "database.createTableIfNotExists()\n",
    "# database.queryBuilder(False, ['SQL'], ['javascript', 'c++'])\n",
    "database.countAllRecords()\n",
    "# database.executeQuery(\"DROP TABLE\" + tableName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsAll = ['datetimeFirst', 'datetimeLast', 'url', 'title', 'salaryAndContract', 'salaryMin', 'salaryMax', 'employer', 'workModes', 'positionLevels', 'offerValidTo', 'location', 'techstackExpected', 'techstackOptional', 'responsibilities', 'requirements', 'optionalRequirements'] # move out of global scope later\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def scrapToDatabase():\n",
    "    timeDeltas = []\n",
    "    inserts = 0\n",
    "    updates = 0\n",
    "    print(database.countAllRecords() + ' records before run')\n",
    "    # for i in range (0,2):\n",
    "    for i in range (len(offers_urls)):\n",
    "        driver.get(offers_urls[i])\n",
    "        if not offerNotFound():\n",
    "            resultsList = getOfferDetails()\n",
    "            outputDictionary = {}\n",
    "            for column, offerDetail in zip(columnsAll, resultsList):\n",
    "                outputDictionary[column] = offerDetail #combine 2 lists into 1 dictionary\n",
    "            # before = time.time()\n",
    "            if database.recordFound(driver.current_url):\n",
    "                database.updateDatetimeLast(driver.current_url)\n",
    "                # print(driver.current_url)\n",
    "                updates += 1\n",
    "            else:\n",
    "                database.insertRecord(outputDictionary) # insert into databas\n",
    "                inserts += 1\n",
    "                # print('insert')\n",
    "            # timeDeltas.append(time.time() - before)\n",
    "            #ending here and starting in an above for/zip loop it takes ~(1/100)s - good enough\n",
    "            print (str(i+1) + '/' + str(len(offers_urls)) + ' done')\n",
    "        else:\n",
    "            print('OFFER NOT FOUND: ' +  driver.current_url)\n",
    "        time.sleep(random.uniform(0.35,0.85)) #Humanize requests frequency\n",
    "    # print(np.mean(timeDeltas))\n",
    "    print(str(inserts) + ' inserts | ' + str(updates) + ' updates')\n",
    "\n",
    "scrapToDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Oct/2024 20:37:28] \"GET /form HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Oct/2024 20:39:08] \"GET /form HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.models.widgets import DataTable, TableColumn\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.embed import components\n",
    "from bokeh.layouts import column\n",
    "\n",
    "def makeBokehPlot(): #Only offers with specified salary?\n",
    "    plot = figure(title=\"Title\", x_axis_label='X', y_axis_label='Y', height = 400, sizing_mode='stretch_width')\n",
    "    plot.line([1, 2, 3, 4, 5], [16, 7, 2, 4, 5], line_width=2)\n",
    "    # plot.line([16, 7, 2, 4, 5], [4, 2, 3, 4, 5], line_width=2)\n",
    "    return plot\n",
    "\n",
    "def makeBokehTable(dataframe):\n",
    "    source = ColumnDataSource(dataframe)\n",
    "    columns = [(TableColumn(field=i, title=i)) for i in dataframe.columns]\n",
    "    table = DataTable(source=source, columns=columns, height = 800, editable=True, sizing_mode=\"stretch_width\")\n",
    "    return table\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def results():\n",
    "    layout = column(makeBokehPlot(), makeBokehTable())\n",
    "    # Get the script and div elements to embed in the template\n",
    "    script, div = components(layout)\n",
    "    # Render the template, passing the components\n",
    "    return render_template(\"app.html\", script=script, div=div, cdn_js=CDN.js_files, cdn_css=CDN.css_files)\n",
    "\n",
    "@app.route('/form', methods=['GET', 'POST'])\n",
    "def form():\n",
    "    if request.method == 'GET':\n",
    "        return render_template(\"form.html\", columnsAll=columnsAll)\n",
    "    \n",
    "    elif request.method == 'POST':\n",
    "        def makeFormOutputDictionary():\n",
    "            formOutputDict = {}\n",
    "            for column in columnsAll:\n",
    "                rowDictionary = {'show': False, 'necessary': None, 'forbidden': None, 'above': None, 'below': None}\n",
    "                #show column\n",
    "                if request.form.get(column+'Show', False): #if not found assign False. Found only if form field not empty\n",
    "                    rowDictionary['show'] = True\n",
    "                #necessary phrase\n",
    "                if request.form.get(column+'Necessary', False):\n",
    "                    phraseNecessary = request.form.get(column+'Necessary')\n",
    "                    phraseNecessary = phraseNecessary.split(\", \")\n",
    "                    rowDictionary['necessary'] = phraseNecessary\n",
    "                #forbidden phrase\n",
    "                if request.form.get(column+'Forbidden', False):\n",
    "                    phraseForbidden = request.form.get(column+'Forbidden')\n",
    "                    phraseForbidden = phraseForbidden.split(\", \")\n",
    "                    rowDictionary['forbidden'] = phraseForbidden\n",
    "                #above\n",
    "                if request.form.get(column+'Above', False):\n",
    "                    rowDictionary['above'] = request.form.get(column+'Above')\n",
    "                    # print('found ' + column+'Above') #\n",
    "                #below\n",
    "                if request.form.get(column+'Below', False):\n",
    "                    rowDictionary['below'] = request.form.get(column+'Below')\n",
    "                    # print('found ' + column+'Below') #\n",
    "                formOutputDict[column] = rowDictionary #append row with column name as a key\n",
    "            return formOutputDict\n",
    "        \n",
    "        def queryBuilder(formDictionary):\n",
    "            querySelectPart = \"SELECT \"\n",
    "            queryMainPart = \"\"\n",
    "            for columnName in formDictionary.keys():\n",
    "                currentColumnDictionary = formDictionary[columnName].items()\n",
    "                for key, value in currentColumnDictionary:\n",
    "                    # SELECT STATEMENT APPENDING\n",
    "                    if key == 'show' and value:\n",
    "                        querySelectPart += columnName + ', '\n",
    "                    #ABOVE & BELOW \n",
    "                    if key == 'above' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" > '\"+value+\"'\"\n",
    "                    if key == 'below' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" < '\"+value+\"'\"\n",
    "                    #NECESSARY/FORBIDDEN PHRASES\n",
    "                    if key == 'necessary' and value: # if list not empty\n",
    "                        for necessaryPhrase in value:\n",
    "                            queryMainPart += \"\\nAND \"+columnName+\" LIKE ('%\"+necessaryPhrase+\"%')\"\n",
    "                    if key == \"forbidden\" and value:\n",
    "                        for forbiddenPhrase in value:\n",
    "                            queryMainPart += \"\\nAND \"+columnName+\" NOT LIKE ('%\"+forbiddenPhrase+\"%')\"\n",
    "            queryMainPart += 'ORDER BY salaryMin'\n",
    "\n",
    "            querySelectPart = querySelectPart[:-2]#remove \", \" from the end\n",
    "            querySelectPart += \" FROM \"+tableName+\" WHERE 1=1\" # to append only ANDs\n",
    "            query = querySelectPart + queryMainPart\n",
    "            queryPlotSelectPart = \"SELECT datetimeFirst, datetimeLast, url, title, salaryMin, salaryMax FROM \"+tableName+\" WHERE 1=1\"#2nd query - always select datetimes and salaries for plotting\n",
    "            # print(queryPlotSelectPart + queryMainPart)\n",
    "            # lines[0] = re.sub(r\",\\d{1,2}\", '', lines[0])\n",
    "            return query\n",
    "        \n",
    "        global df #delete later\n",
    "        df = database.queryToDataframe(queryBuilder(makeFormOutputDictionary()))\n",
    "        # df.to_csv('results.csv', sep=',', encoding='utf-8-sig', index=True, header=True) #export to CSV\n",
    "        # print(len(df))\n",
    "        \n",
    "\n",
    "        \n",
    "        layout = column(makeBokehPlot(), makeBokehTable(df))\n",
    "        # Get the script and div elements to embed in the template\n",
    "        script, div = components(layout)\n",
    "        # return makeFormOutputDictionary()\n",
    "        return render_template(\"app.html\", script=script, div=div, cdn_js=CDN.js_files, cdn_css=CDN.css_files)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)#JUPYTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      4 days 22:19:15\n",
      "1      4 days 22:19:16\n",
      "2     17 days 00:51:08\n",
      "3     12 days 23:11:22\n",
      "4     12 days 23:11:26\n",
      "            ...       \n",
      "202    0 days 00:00:00\n",
      "203    0 days 00:00:00\n",
      "204    0 days 00:00:00\n",
      "205    0 days 00:00:00\n",
      "206    0 days 00:00:00\n",
      "Length: 207, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# # ADJUST QUERY BUILDER:\n",
    "# def queryBuilder(formOutput):\n",
    "#     fullQuery = \"SELECT datetimeLast, techstackExpected FROM \" + tableName + \" WHERE 1=1\" #Includes WHERE to always append a line starting with AND\n",
    "#     if onlyLastSeenLessThan24hAgo:\n",
    "#         fullQuery += \"\\nAND (JULIANDAY(strftime('%Y-%m-%d %H:%M:%S', DATETIME('now', 'localtime'))) - JULIANDAY(datetimeLast)) * 24 < 24\" \n",
    "#     if keywordsNecessary:\n",
    "#         for keyword in keywordsNecessary:\n",
    "#             fullQuery += \"\\nAND (techstackExpected LIKE ('%\"+keyword+\"%') OR requirements LIKE ('%\"+keyword+\"%'))\"\n",
    "#     if keywordsUnacceptable:\n",
    "#         for keyword in keywordsUnacceptable:\n",
    "#             fullQuery += \"\\nAND techstackExpected NOT LIKE ('%\"+keyword+\"%') AND requirements NOT LIKE ('%\"+keyword+\"%')\"\n",
    "#     fullQuery += ';'\n",
    "#     print(fullQuery)\n",
    "\n",
    "## TODO:\n",
    "# waluty -> zł? chyba nie ma innej waluty na stronie\n",
    "# elif group.text[0:8] == 'OPTIONAL': #never saw polish version yet\n",
    "# wykresy posortowane po salaryMin/Max\n",
    "# wykresy po zliczeniu słów?\n",
    "# paramsy takie jak %VAT do ustawienia\n",
    "# download csv table?\n",
    "# form OR operator (/)?\n",
    "# query ORDER BY part potrzebne?\n",
    "\n",
    "\n",
    "# list = df[['datetimeFirst', 'datetimeLast']].values.tolist()\n",
    "# print(list)\n",
    "\n",
    "ls = pd.to_datetime(df[\"datetimeFirst\"])\n",
    "ls = pd.to_datetime(df[\"datetimeLast\"])-pd.to_datetime(df[\"datetimeFirst\"])\n",
    "print(ls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
