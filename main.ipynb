{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a browser and set the cookies from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True # recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "\n",
    "# ChromeDriver should match browser version. If outdated download from:\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "def setCookiesFromJson():  \n",
    "    try:\n",
    "        DRIVER.get(BASE_URL) #RUN BROWSER\n",
    "        currentUrlDomain = DRIVER.current_url\n",
    "        currentUrlDomain = re.search(r'^https?://([^/]+)', currentUrlDomain)\n",
    "        currentUrlDomain = currentUrlDomain.group(1)  \n",
    "        currentUrlDomain = re.sub(r'^www\\.', '', currentUrlDomain)\n",
    "        currentUrlDomain = re.sub(r'^\\.', '', currentUrlDomain)\n",
    "        # print(currentUrlDomain)\n",
    "        with open('cookies.json', 'r', newline='') as inputdata:\n",
    "            cookies = json.load(inputdata)\n",
    "            cookiesAdded = 0\n",
    "            for cookie in cookies: #works only after driver.get\n",
    "                if re.match(r\".?\"+currentUrlDomain, cookie['domain']): # can only add cookies for current domain\n",
    "                    DRIVER.add_cookie(cookie)\n",
    "                    cookiesAdded += 1\n",
    "            if cookiesAdded > 0:\n",
    "                DRIVER.refresh() # to load cookies\n",
    "                return {'success':True, 'functionDone':True, 'message':'cookies for ' + currentUrlDomain + ' successfully set'}\n",
    "            elif (cookiesAdded == 0):\n",
    "                return {'success':False, 'functionDone':True, 'message':'no cookies for ' + currentUrlDomain + ' found in cookies.json'}\n",
    "    except Exception as exception:\n",
    "        return {'success':False, 'functionDone':True, 'message':str(exception)} # 'functionDone':True because it's not necessary\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "chrome_options.add_argument(\"window-size=800,1000\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "DRIVER = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "BASE_URL = \"https://justjoin.it/job-offers/bialystok\"\n",
    "DRIVER.get(BASE_URL)\n",
    "setCookiesFromJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the URLs from all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getLastOfferIndex():\n",
    "#     try:\n",
    "#         DRIVER.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # scroll to the bottom\n",
    "#         offersList = DRIVER.find_element(By.ID, 'up-offers-list')\n",
    "#         offers = offersList.find_elements(By.XPATH, '//li[@data-index]') # amount depends on screen height \n",
    "#         lastIndex = offers[-1].get_attribute('data-index')\n",
    "#         return lastIndex\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return\n",
    "\n",
    "def offerNotFound():\n",
    "    try:\n",
    "        offerContent = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-tnvghs')\n",
    "        topContainer = offerContent.find_element(By.CSS_SELECTOR, 'div') # 1st div\n",
    "        # NEED TO FIND 'OFFER NOT FOUND MSG AND CHECK WHICH DIVS DOES IT HAVE\n",
    "        # topDiv = topContainer.find_element(By.XPATH, \".//*[contains(@class, 'css-10x887j')]\")\n",
    "        return False # if topDiv found, offer is there\n",
    "    except:\n",
    "        return True\n",
    "# offerNotFound()\n",
    "\n",
    "def anyOffersOnTheList():\n",
    "    try:\n",
    "        # offersList = DRIVER.find_element(By.XPATH, '//*[@data-test-id=\"virtuoso-item-list\"]') #changed ~25.12.2024\n",
    "        offersList = DRIVER.find_element(By.ID, 'up-offers-list')\n",
    "        offers = offersList.find_elements(By.XPATH, '//li[@data-index]')\n",
    "        if len(offers) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return False\n",
    "\n",
    "offersUrlsWithIndexesList = [{'index':-1, 'url':''}]\n",
    "# indexesTemp = []\n",
    "\n",
    "def fetchCurrentlyVisibleOffersUrls(): # just the ones currently rendered in browser\n",
    "    try:\n",
    "        offersList = DRIVER.find_element(By.ID, 'up-offers-list')\n",
    "        # offersList = offersList.find_elements(By.XPATH, '//ul')\n",
    "        offers = offersList.find_elements(By.XPATH, '//li[@data-index]') # amount depends on screen height \n",
    "        for offer in offers: # ever-loading div among them \n",
    "            try:\n",
    "                index = offer.get_attribute('data-index')\n",
    "                href = offer.find_element(By.XPATH, \".//div/div/a\").get_property(\"href\")\n",
    "\n",
    "                def foundAmongSavedIndexes():\n",
    "                    for i in range (len(offersUrlsWithIndexesList[-30:])): # 30 last offers (or less if len < 30)\n",
    "                        if index == offersUrlsWithIndexesList[-i - 1]['index']: # decrementing from the end\n",
    "                            return True\n",
    "                    return False # not found if reached this return\n",
    "                \n",
    "                if not foundAmongSavedIndexes():\n",
    "                    offersUrlsWithIndexesList.append({'index':index, 'url':href})\n",
    "                    \n",
    "            except:\n",
    "                pass #if url not found\n",
    "        if len(offersUrlsWithIndexesList) >=1:\n",
    "            print(int(offersUrlsWithIndexesList[-1]['index']) - int(offersUrlsWithIndexesList[0]['index']) + 1, len(offersUrlsWithIndexesList))\n",
    "            print('first and last offersUrlsWithIndexesList: ', offersUrlsWithIndexesList[0]['index'], offersUrlsWithIndexesList[-1]['index'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "def fetchAllOffersUrls():\n",
    "    noNewResultsCounter = 0\n",
    "    lastSeenIndex = 0\n",
    "    if not anyOffersOnTheList():\n",
    "        return\n",
    "    \n",
    "    DRIVER.execute_script(\"window.scrollTo(0, 0);\") # scroll to the top\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    while True:\n",
    "        # print(lastSeenIndex)\n",
    "        fetchCurrentlyVisibleOffersUrls() #updates offersUrlsWithIndexesList\n",
    "\n",
    "        if (lastSeenIndex == offersUrlsWithIndexesList[-1]['index']):\n",
    "            noNewResultsCounter += 1\n",
    "            DRIVER.execute_script(\"window.scrollBy(0, -2*innerHeight);\") # for some reason scrolling up helps this fucking site to load the bottom\n",
    "            time.sleep(1)\n",
    "            DRIVER.execute_script(\"window.scrollBy(0, 3*innerHeight);\") # scroll to the bottom\n",
    "            print('noNewResults')\n",
    "            # print(offersUrlsWithIndexesList[0]['index'], offersUrlsWithIndexesList[-1]['index'])\n",
    "        else: # reset counter\n",
    "            noNewResultsCounter = 0\n",
    "        if noNewResultsCounter >= 5: # or int(lastSeenIndex) >= 10: # END IF NO NEW RESULTS FEW TIMES\n",
    "            # fetchCurrentlyVisibleOffersUrls()\n",
    "            del offersUrlsWithIndexesList[0] # this was a placeholder to avoid more ifs\n",
    "            print('RETURN')\n",
    "            #print(int(offersUrlsWithIndexesList[-1]['index']) - int(offersUrlsWithIndexesList[0]['index']) + 1, len(offersUrlsWithIndexesList))\n",
    "            print('first and last offersUrlsWithIndexesList: ', offersUrlsWithIndexesList[0]['index'], offersUrlsWithIndexesList[-1]['index'])\n",
    "            return\n",
    "        \n",
    "        lastSeenIndex = offersUrlsWithIndexesList[-1]['index']\n",
    "        time.sleep(0.5)\n",
    "        DRIVER.execute_script(\"window.scrollBy(0, innerHeight);\")\n",
    "\n",
    "fetchAllOffersUrls()\n",
    "# fetchCurrentlyVisibleOffersUrls()\n",
    "# print(offersUrlsWithIndexesList)\n",
    "# print(offersUrlsWithIndexesList['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# while True:\n",
    "#     DRIVER.execute_script(\"window.scrollTo(0, 0);\") # scroll to the top\n",
    "#     time.sleep(0.1)\n",
    "#     DRIVER.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # scroll to the bottom\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "# print(offersUrlsWithIndexesList[-1]['index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse offer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     jobTitle = DRIVER.find_elements(By.CSS_SELECTOR, '.css-sy4ig6')\n",
    "#     print(jobTitle)\n",
    "#     jobTitle = jobTitle.text\n",
    "# except:\n",
    "#     jobTitle = None\n",
    "# print(jobTitle)\n",
    "\n",
    "# singleLocation = https://justjoin.it/job-offer/emagine-polska-technical-architect-warszawa-architecture\n",
    "\n",
    "def getOfferDetails():\n",
    "    # BASIC PARAMETERS WHICH SHOULD ALWAYS BE NOT EMPTY ON THE SITE\n",
    "    try:\n",
    "        offerContent = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-tnvghs')\n",
    "        topContainer = offerContent.find_element(By.CSS_SELECTOR, 'div')\n",
    "        topDiv = topContainer.find_element(By.XPATH, \".//*[contains(@class, 'css-10x887j')]\") # .// = as deep as necessary\n",
    "    except Exception as exception:\n",
    "        # print(exception)\n",
    "        return # no point of continuing\n",
    "    try:\n",
    "        jobTitle = topDiv.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "        # print(jobTitle)\n",
    "        employerAndLocationDiv = topDiv.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-yd5zxy') \n",
    "        employer = employerAndLocationDiv.find_element(By.XPATH, './/h2').text # look for h2 as deep as necessary\n",
    "        # print(employer) # name=\"multilocation_button\"\n",
    "    except:\n",
    "        jobTitle, employer = '', ''\n",
    "\n",
    "    try:\n",
    "        location = employerAndLocationDiv.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-mswf74')[1].text # first one is employer\n",
    "        location = re.sub(r'\\+[0-9]+$', '', location) #remove '+x' where x is int\n",
    "    except:\n",
    "        location = ''\n",
    "    #try clicking for more locations\n",
    "    try:\n",
    "        locationButton = employerAndLocationDiv.find_element(\"xpath\", '//*[@name=\"multilocation_button\"]')\n",
    "        locationButton.click()\n",
    "        locationsMenu = offerContent.find_element(\"xpath\", '//ul[@role=\"menu\"]')\n",
    "        # locationsMenu = locationsMenu.find_elements(By.CSS_SELECTOR, 'li')\n",
    "        location += '\\n' + locationsMenu.text # TEXT EMPTY WHEN MINIMIZED!\n",
    "    except Exception as exception:\n",
    "        pass\n",
    "    # print(location)\n",
    "\n",
    "    #SALARY\n",
    "    try:\n",
    "        salaryAndContract = topContainer.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-1km0bek').text\n",
    "    except:\n",
    "        salaryAndContract= ''\n",
    "\n",
    "    salaryMinAndMax = [None, None] # Nones as these are INTs in DB\n",
    "    if salaryAndContract != '':\n",
    "        try: #to recalculate salary to [PLN/month net]\n",
    "            grossToNetMultiplier = 0.7\n",
    "            hoursPerMonthInFullTimeJob = 168\n",
    "            lines = salaryAndContract.splitlines()[0] # There could be multiple salaries depending on contract type though. It will be in salaryAndContract anyway\n",
    "            splitValues = re.split(r'-', lines) # split on dash for min and max\n",
    "\n",
    "            for i in range(len(splitValues)):\n",
    "                splitValues[i] = splitValues[i].replace(\" \", \"\") # remove spaces\n",
    "                splitValues[i] = re.sub(r\",\\d{1,2}\", '', splitValues[i]) # removes , and /d{1 to 2 occurrences}  (needed when salary as 123,45)\n",
    "                salaryMinAndMax[i] = re.search(r\"\\d+\", splitValues[i]).group() # r = raw, \\d+ = at least 1 digit, group() contains results\n",
    "                \n",
    "            if re.findall(\"brutto\", lines[1]) or re.findall(\"gross\", lines[1]): # gross -> net\n",
    "                salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "                # print(salaryMinAndMax)\n",
    "            if re.findall(\"godz\", lines[1]) or re.findall(\"hr.\", lines[1]): # hr -> month\n",
    "                salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str\n",
    "\n",
    "            salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "        except Exception as exception:\n",
    "            pass    # salaryMinAndMax = [None, None]\n",
    "    # print(salaryMinAndMax)\n",
    "\n",
    "    # print(salaryAndContract)\n",
    "    workModes = ''\n",
    "    positionLevels = ''\n",
    "\n",
    "    try:\n",
    "        # MuiBox-root css-ktfb40\n",
    "        fourRectanglesContainer = offerContent.find_elements(By.XPATH, \"./div\")[1] # only child divs, not grandchild or further - 1 level down\n",
    "        # print(fourRectanglesContainer.text)\n",
    "        fourRectangles = fourRectanglesContainer.find_elements(By.XPATH, \"./div\")\n",
    "\n",
    "        for i in range(len(fourRectangles)):\n",
    "            fourRectangles[i] = fourRectangles[i].find_elements(By.XPATH, \"./div\")[1] # second child div (not grandchild or further)\n",
    "            fourRectangles[i] = fourRectangles[i].find_elements(By.XPATH, \"./div\")[1].text\n",
    "            # print(fourRectangles[i])\n",
    "        salaryAndContract += '\\n' + fourRectangles[0] + ' | ' + fourRectangles[2]\n",
    "        positionLevels = fourRectangles[1]\n",
    "        workModes = fourRectangles[3]\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass\n",
    "    # print(salaryAndContract)\n",
    "    # print(workModes, positionLevels + '\\n')\n",
    "\n",
    "    #TECHSTACK\n",
    "    techstackExpected, techstackOptional = '', ''\n",
    "    try:\n",
    "        techstackDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[0]\n",
    "        techstackDiv = techstackDiv.find_element(By.CSS_SELECTOR, 'div')\n",
    "        technologies = techstackDiv.find_elements(By.XPATH, './/h4') # look for h4 in all children elements\n",
    "        levels = techstackDiv.find_elements(By.XPATH, './/span') # look for h4 in all children elements\n",
    "        for i in range(len(technologies)):\n",
    "            techWithLvl = technologies[i].text + ' - ' + levels[i].text\n",
    "            # print(techWithLvl)\n",
    "            if levels[i].text == 'Nice To Have': # or levels[i].text == 'Junior'\n",
    "                techstackOptional += '\\n' + techWithLvl\n",
    "            else: # -(nice to have)/junior/regular/advanced/master\n",
    "                techstackExpected += '\\n' + techWithLvl\n",
    "\n",
    "        techstackOptional = re.sub(r\"^\\n\", '', techstackOptional)\n",
    "        techstackExpected = re.sub(r\"^\\n\", '', techstackExpected)\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass # leave empty strs\n",
    "    # print(techstackExpected + '\\n\\n' + techstackOptional)\n",
    "\n",
    "    # ==================== DO THIS NOW ====================\n",
    "    offerValidTo = '' # REMOVE FROM DB?\n",
    "    fullDescription = '' # ADD TO DB\n",
    "    responsibilities, requirements, optionalRequirements, theyOffer = '', '', '', ''\n",
    "\n",
    "    optionalRequirementsKeywords = ['nice to', 'optional', 'ideal', 'preferr', 'asset', 'appreciat', 'atut', 'dodatk', 'mile widzi']\n",
    "    requirementsKeywords = ['require', 'expect', 'skill', 'look', 'qualifications', 'experience', 'must', 'competen', 'wymaga', 'oczek', 'umiejętn', 'aplikuj, jeśli', 'oczekuj', 'potrzeb', 'szukamy', 'kompeten']\n",
    "    responsibilitiesKeywords = ['responsib', 'task', 'role', 'project', 'obowiązk', 'zadani', 'projek']\n",
    "    whatTheyOfferKeywords = ['offer', 'benefit' 'oferuj', 'oferow']\n",
    "\n",
    "    allKeywordsDict = {'optionalRequirementsKeywords':optionalRequirementsKeywords, 'requirementsKeywords':requirementsKeywords, 'responsibilitiesKeywords':responsibilitiesKeywords}\n",
    "\n",
    "    try:\n",
    "        descriptionDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[1]\n",
    "        descriptionDiv = descriptionDiv.find_elements(By.XPATH, \"./div\")[1] # second child div\n",
    "        fullDescription = descriptionDiv.text\n",
    "        # print(r\"{}\".format(fullDescription))\n",
    "        paragraphs = re.split(r\"\\n{2,}\", fullDescription) # split on 2 or more newlines\n",
    "\n",
    "        # USUALLY THE ABOVE SPLITTING IS ENOUGH, BUT IF NOT TRY FINDING PARAGRAPHS ANOTHER WAY\n",
    "        if len(paragraphs) < 3: # 1 is possible minimum\n",
    "            # print('LEN TOO SHORT: ' + str(len(paragraphs)))\n",
    "            # paragraphs = re.split(r\"(^|\\n) +\", fullDescription) # split on 1 or more spaces at the line beginning\n",
    "            paragraphs = re.split(r\"((^|\\n) +|\\n{2,})\", fullDescription) # split on 1 or more spaces at the line beginning OR on 2 or more newlines\n",
    "        # print(paragraphs)\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            if not paragraph or re.search(r\"^\\s*$\", paragraph): # \\s matches Unicode whitespace characters. This includes [ \\t\\n\\r\\f\\v] and more\n",
    "                continue # don't try to analyze an empty sting, go with next loop iteration\n",
    "            # look for keywords in the 1st line of text\n",
    "            header = paragraph.splitlines()[0] # first line\n",
    "            # print('=====================')\n",
    "            # print(header)\n",
    "            # print(paragraph)\n",
    "            for keywordsCategory in allKeywordsDict.keys():\n",
    "                # print(keywordsCategory)\n",
    "                for keyword in allKeywordsDict[keywordsCategory]:\n",
    "                    # if keyword found in header\n",
    "                    # if re.search(rf'\\b{re.escape(keyword)}\\b', header, re.IGNORECASE): # \\b = boundaries - matches whole words, regardless of punctuation or position in the string # escapes = escape regex reserved symbols\n",
    "                    if re.search(rf'.*{re.escape(keyword)}.*', header, re.IGNORECASE): # .* = any symbol any number of times\n",
    "                        # print('found ' + keyword)\n",
    "                        if keywordsCategory =='optionalRequirementsKeywords': # check this first as it's more specific than requirements and contains similar keywords\n",
    "                            optionalRequirements += paragraph\n",
    "                        elif keywordsCategory =='requirementsKeywords':\n",
    "                            requirements += paragraph\n",
    "                        elif keywordsCategory =='responsibilitiesKeywords':\n",
    "                            responsibilities += paragraph\n",
    "                        elif keywordsCategory == 'whatTheyOfferKeywords':\n",
    "                            whatTheyOfferKeywords += paragraph\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass\n",
    "\n",
    "    # print('\\n\\n'+ responsibilities +'\\n\\n'+ requirements +'\\n\\n'+ optionalRequirements)\n",
    "    datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return [datetimeNow, datetimeNow, DRIVER.current_url, jobTitle, salaryAndContract, salaryMinAndMax[0], salaryMinAndMax[1], employer, workModes, positionLevels, offerValidTo, location, techstackExpected, techstackOptional, responsibilities, requirements, optionalRequirements]\n",
    "\n",
    "# testing below\n",
    "# DRIVER.get('https://justjoin.it/job-offer/jit-team-senior-frontend-developer-bialystok-javascript')\n",
    "# DRIVER.switch_to.window(DRIVER.window_handles[-1])\n",
    "# getOfferDetails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(resultsDataFrame.employer)\n",
    "# # resultsDataFrame.to_sql('offers', 'resultsDf.db') #alchemy needed\n",
    "import sqlite3\n",
    "\n",
    "tableName = 'test4' #not needed as an argument\n",
    "\n",
    "class database():\n",
    "    def createTableIfNotExists(): #if not exists\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS \" + tableName + \"\"\" (\n",
    "                    datetimeFirst TEXT,\n",
    "                    datetimeLast TEXT,\n",
    "                    url TEXT,\n",
    "                    title TEXT, \n",
    "                    salaryAndContract TEXT,\n",
    "                    salaryMin INT,\n",
    "                    salaryMax INT,\n",
    "                    employer TEXT,\n",
    "                    workModes TEXT,\n",
    "                    positionLevels TEXT,\n",
    "                    offerValidTo TEXT,\n",
    "                    location TEXT,\n",
    "                    techstackExpected TEXT,\n",
    "                    techstackOptional TEXT,\n",
    "                    responsibilities TEXT,\n",
    "                    requirements TEXT,\n",
    "                    optionalRequirements TEXT);\"\"\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def selectAll():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM\" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def executeQuery(query):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def recordFound(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        # print(urlPartToCompare)\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT datetimeFirst FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if len(result) >0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def insertRecord(dictionary):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"INSERT INTO \" + tableName + \" VALUES (:datetimeFirst, :datetimeLast, :url, :title, :salaryAndContract, :salaryMin, :salaryMax, :employer, :workModes, :positionLevels, :offerValidTo, :location, :techstackExpected, :techstackOptional, :responsibilities, :requirements, :optionalRequirements)\", dictionary)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def updateDatetimeLast(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"UPDATE \" + tableName + \" SET datetimeLast = '\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")) + \"'  WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        # cursor.execute(\"SELECT datetimeLast FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def countAllRecords():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT COUNT (*) FROM \" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        resultTuple = cursor.fetchall()[0]\n",
    "        (count,) = resultTuple #unpacking tuple\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return str(count)\n",
    "\n",
    "    def queryToDataframe(fullQuery):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        # df = pd.read_sql(\"SELECT datetimeFirst, datetimeLast FROM \" +tableName+ \";\", con=connection)\n",
    "        df = pd.read_sql(fullQuery, con=connection)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        # print('\\n'+str(len(cursor.fetchall())) + ' records found')\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return df\n",
    "    \n",
    "database.createTableIfNotExists()\n",
    "database.countAllRecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsAll = ['datetimeFirst', 'datetimeLast', 'url', 'title', 'salaryAndContract', 'salaryMin', 'salaryMax', 'employer', 'workModes', 'positionLevels', 'offerValidTo', 'location', 'techstackExpected', 'techstackOptional', 'responsibilities', 'requirements', 'optionalRequirements'] # move out of global scope later\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def scrapToDatabase():\n",
    "    timeDeltas = []\n",
    "    inserts = 0\n",
    "    updates = 0\n",
    "    print(database.countAllRecords() + ' records before run')\n",
    "    # for i in range (0,2):\n",
    "    for i in range (len(offersUrlsWithIndexesList)):\n",
    "        DRIVER.get(offersUrlsWithIndexesList[i]['url'])\n",
    "        if not offerNotFound():\n",
    "            resultsList = getOfferDetails()\n",
    "            print(resultsList)\n",
    "            outputDictionary = {}\n",
    "            for column, offerDetail in zip(columnsAll, resultsList):\n",
    "                outputDictionary[column] = offerDetail #combine 2 lists into 1 dictionary\n",
    "            before = time.time()\n",
    "            if database.recordFound(DRIVER.current_url):\n",
    "                database.updateDatetimeLast(DRIVER.current_url)\n",
    "                # print(driver.current_url)\n",
    "                updates += 1\n",
    "            else:\n",
    "                database.insertRecord(outputDictionary) # insert into databas\n",
    "                inserts += 1\n",
    "                # print('insert')\n",
    "            timeDeltas.append(time.time() - before)\n",
    "            #ending here and starting in an above for/zip loop it takes ~(1/100)s - good enough\n",
    "            print (str(i+1) + '/' + str(len(offersUrlsWithIndexesList)) + ' done')\n",
    "        else:\n",
    "            print('OFFER NOT FOUND: ' +  DRIVER.current_url)\n",
    "        time.sleep(random.uniform(0.35,0.85)) #Humanize requests frequency\n",
    "    print(np.mean(timeDeltas))\n",
    "    print(str(inserts) + ' inserts | ' + str(updates) + ' updates')\n",
    "\n",
    "scrapToDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, send_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.models.widgets import DataTable, TableColumn\n",
    "from bokeh.models import ColumnDataSource, WheelZoomTool, HTMLTemplateFormatter, HoverTool, TapTool, Range1d, LinearAxis\n",
    "from bokeh.embed import json_item\n",
    "from bokeh.io import curdoc #for dark theme\n",
    "import io #for a csv buffer\n",
    "\n",
    "def makeBokehPlot(dataframe): #Only offers with specified salary?\n",
    "    # len(dataframe) >=1 at this point \n",
    "    # dataframe already ordered by (salaryMin+SalaryMax)/2 ASC\n",
    "\n",
    "    pd.options.mode.copy_on_write = True #recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "    nonNanRowsDf = dataframe[dataframe['salaryMin'].notna()]\n",
    "    nanRowsDf = dataframe[dataframe['salaryMin'].isna()]\n",
    "\n",
    "    # SPECIFY UNSPECIFIED BARS HEIGHT\n",
    "    if len(nonNanRowsDf) > 0: #otherwise division by 0 possible\n",
    "        lookUpToValues = 2 #how many values to count average\n",
    "        avgOfNLowestMinSalaries = nonNanRowsDf['salaryMin'].head(lookUpToValues).tolist() #select up to 2 values\n",
    "        avgOfNLowestMinSalaries = sum(avgOfNLowestMinSalaries) / len(avgOfNLowestMinSalaries) #avg\n",
    "        avgOfNLowestMaxSalaries = nonNanRowsDf['salaryMax'].head(lookUpToValues).tolist() #select up to 2 values\n",
    "        avgOfNLowestMaxSalaries = sum(avgOfNLowestMaxSalaries) / len(avgOfNLowestMaxSalaries) #avg\n",
    "        nanRowsDf['salaryMin'] = nanRowsDf['salaryMin'].fillna(avgOfNLowestMinSalaries) #replace nulls with values\n",
    "        nanRowsDf['salaryMax'] = nanRowsDf['salaryMax'].fillna(avgOfNLowestMaxSalaries)\n",
    "    else: #if only unspecified salaries foud\n",
    "        avgOfNLowestMinSalaries = 4200 #some value to plot\n",
    "        avgOfNLowestMaxSalaries = 4200\n",
    "        nanRowsDf['salaryMin'] = nanRowsDf['salaryMin'].fillna(avgOfNLowestMinSalaries) #replace nulls with values\n",
    "        nanRowsDf['salaryMax'] = nanRowsDf['salaryMax'].fillna(avgOfNLowestMaxSalaries)\n",
    "        \n",
    "    dataSalaryUnspecified = {\n",
    "        'x': nanRowsDf.index.tolist(),\n",
    "        'title': nanRowsDf['title'].values.tolist(),\n",
    "        'activeFor': [(dtstr.days) for dtstr in (pd.to_datetime(nanRowsDf[\"datetimeLast\"])-pd.to_datetime(nanRowsDf[\"datetimeFirst\"])).tolist()], #.days shows only days\n",
    "        'salaryAvg': [((avgOfNLowestMinSalaries+avgOfNLowestMaxSalaries)/2) for i in range (len(nanRowsDf))]\n",
    "    }\n",
    "    dataSalarySpecified = {\n",
    "        'x': nonNanRowsDf.index.tolist(),\n",
    "        'title': nonNanRowsDf['title'].values.tolist(),\n",
    "        'activeFor': [(dtstr.days) for dtstr in (pd.to_datetime(nonNanRowsDf[\"datetimeLast\"])-pd.to_datetime(nonNanRowsDf[\"datetimeFirst\"])).tolist()], #.days shows only days\n",
    "        'salaryMin': nonNanRowsDf['salaryMin'].values.tolist(),\n",
    "        'salaryMax': nonNanRowsDf['salaryMax'].values.tolist(),\n",
    "        'salaryAvg': [(a + b) / 2 for a, b in zip(nonNanRowsDf['salaryMin'].values.tolist(), nonNanRowsDf['salaryMax'].values.tolist())],\n",
    "    }\n",
    "\n",
    "    #Calculate ranges - SAFE MAX by declaring default values used if empty list\n",
    "    maxActiveFor = int(max(max(dataSalaryUnspecified['activeFor'], default=0) , max(dataSalarySpecified['activeFor'], default=0))) +1 #\n",
    "    maxSalary = max(max(dataSalaryUnspecified['salaryAvg'], default=0) , max(dataSalarySpecified['salaryMax'], default=0)) * 1.05\n",
    "\n",
    "    sourceSalaryUnspecified = ColumnDataSource(dataSalaryUnspecified) #2 data sources\n",
    "    sourceSalarySpecified = ColumnDataSource(dataSalarySpecified) #2 data sources\n",
    "    plot = figure(title=\"\", x_axis_label='Offer index', y_axis_label='Salary', height = 400, sizing_mode='stretch_width')\n",
    "    plot.y_range = Range1d(start=0 - 1, end=maxSalary) # * 1.2 to fit the bars\n",
    "    plot.x_range = Range1d(start=0 - 1, end=int(len(dataframe))) #too much empty space by default\n",
    "    plot.extra_y_ranges = {\"y2\": Range1d(start=0, end=maxActiveFor)} #add 1 day\n",
    "    #COLORS\n",
    "    salaryUnspecifiedColor = 'rgb(60,60,160)'\n",
    "    salarySpecifiedColor = 'rgb(80,80,220)'\n",
    "    # daysActiveColor = 'rgb(30,150,30)'\n",
    "    daysActiveColor = 'rgb(60,100,40)'\n",
    "    # SALARY UNSPECIFIED BARS\n",
    "    plot.vbar('x', top = 'salaryAvg', width = 0.70, source = sourceSalaryUnspecified, color=salaryUnspecifiedColor, alpha = 1) # MAIN BAR\n",
    "    plot.vbar('x', top = 'activeFor', y_range_name=\"y2\", source = sourceSalaryUnspecified, color=daysActiveColor, alpha = 0.15, width=0.90) # Active for\n",
    "    # plot.segment(x0='x', y0='salaryMin', x1='x', y1='salaryMax', source=sourceSalaryUnspecified, line_width=2, color='black', alpha = 0.5) #Error bar\n",
    "    # SALARY SPECIFIED BARS\n",
    "    plot.vbar('x', top = 'salaryAvg', width = 0.70, source = sourceSalarySpecified, color=salarySpecifiedColor, alpha = 1) # MAIN BAR\n",
    "    plot.vbar('x', top = 'activeFor', y_range_name=\"y2\", source = sourceSalarySpecified, color=daysActiveColor, alpha = 0.15, width=0.90) # Active for\n",
    "    plot.segment(x0='x', y0='salaryMin', x1='x', y1='salaryMax', source=sourceSalarySpecified, line_width=1.5, color='black', alpha=0.75) #Error bar\n",
    "    \n",
    "    plot.add_layout(LinearAxis(y_range_name=\"y2\", axis_label=\"Days adtive\"), 'right') # Add the second y-axis to the right\n",
    "    \n",
    "    # Configure minor gridlines\n",
    "    plot.xgrid.minor_grid_line_color = 'rgb(80,80,80)'\n",
    "    plot.ygrid.minor_grid_line_color = 'rgb(80,80,80)'\n",
    "    plot.xgrid.minor_grid_line_alpha = 0.5 # Opacity\n",
    "    plot.ygrid.minor_grid_line_alpha = 0.5\n",
    "\n",
    "    taptool = TapTool() #highlight on tap\n",
    "    wheel_zoom = WheelZoomTool()\n",
    "    plot.toolbar.active_scroll = wheel_zoom\n",
    "    hoverSalaryUnpecified = HoverTool(tooltips=[(\"Offer index:\", \"@x\"), (\"Job title:\", \"@title\"), (\"Salary:\", \"Unspecified\"), (\"Active for:\", \"@activeFor days\")])\n",
    "    hoverSalaryUnpecified.renderers = [plot.renderers[0]]# hover tool only on the salary bars\n",
    "    hoverSalarySpecified = HoverTool(tooltips=[(\"Offer index:\", \"@x\"), (\"Job title:\", \"@title\"), (\"Min/Avg/Max:\", \"@salaryMin{0.}/@salaryAvg{0.}/@salaryMax{0.}\"), (\"Active for:\", \"@activeFor days\")]) #{0} = no decimals\n",
    "    hoverSalarySpecified.renderers = [plot.renderers[2]]# hover tool only on the salary bars\n",
    "    plot.add_tools(hoverSalarySpecified, hoverSalaryUnpecified, taptool) #wheel_zoom removed for now\n",
    "    #DARK THEME\n",
    "    curdoc().theme = 'dark_minimal'\n",
    "    curdoc().add_root(plot) #to apply the theme\n",
    "    return plot\n",
    "\n",
    "def makeBokehTable(dataframe):\n",
    "    source = ColumnDataSource(dataframe)\n",
    "    columns = []\n",
    "    for column in dataframe.columns:\n",
    "        if column == 'url': # to make a hyperlink\n",
    "            columns.append(TableColumn(field=column, title=column, formatter=HTMLTemplateFormatter(template=\"\"\"<a href=\"<%= value %>\" target=\"_blank\"><%= value %></a>\"\"\")))\n",
    "        else:\n",
    "            columns.append(TableColumn(field=column, title=column))     \n",
    "    table = DataTable(source=source, columns=columns, height = 800, editable=True, sizing_mode=\"stretch_width\")\n",
    "    return table\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/downloadCsv')\n",
    "def downloadCsv():\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csvName = \"jobScrappingResults \" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")) + \".csv\"\n",
    "    # Save the DataFrame to a CSV in memory\n",
    "    buffer = io.BytesIO() #buffer for a csv file to avoid saving csv on a disk\n",
    "    dataframeTable.to_csv(buffer, sep=',', encoding='utf-8-sig', index=True, header=True)\n",
    "    buffer.seek(0)  # Reset buffer position to the beginning\n",
    "    # Send the CSV file as a downloadable response\n",
    "    return send_file(buffer, as_attachment=True, download_name=csvName, mimetype='text/csv')\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def form():\n",
    "    if request.method == 'GET':\n",
    "        # return render_template(\"form.html\", columnsAll=columnsAll)\n",
    "        return render_template(\"app.html\", columnsAll=columnsAll, resources=CDN.render())\n",
    "    \n",
    "    elif request.method == 'POST':\n",
    "        def makeFormOutputDictionary():\n",
    "            formDictFromJson = request.get_json() #get form values from a request\n",
    "            outputDict = {}\n",
    "            for column in columnsAll:\n",
    "                rowDictionary = {'show': False, 'necessary': None, 'forbidden': None, 'above': None, 'below': None}\n",
    "                #show column\n",
    "                if formDictFromJson.get(column+'Show', False): #if not found assign False. Found only if form field not empty\n",
    "                    rowDictionary['show'] = True\n",
    "                #necessary phrase\n",
    "                if formDictFromJson.get(column+'Necessary', False):\n",
    "                    phraseNecessary = formDictFromJson.get(column+'Necessary')\n",
    "                    # phraseNecessary = phraseNecessary.split(\", \") #delete\n",
    "                    rowDictionary['necessary'] = phraseNecessary\n",
    "                #forbidden phrase\n",
    "                if formDictFromJson.get(column+'Forbidden', False):\n",
    "                    phraseForbidden = formDictFromJson.get(column+'Forbidden')\n",
    "                    # phraseForbidden = phraseForbidden.split(\", \") #delete\n",
    "                    rowDictionary['forbidden'] = phraseForbidden\n",
    "                #above\n",
    "                if formDictFromJson.get(column+'Above', False):\n",
    "                    rowDictionary['above'] = formDictFromJson.get(column+'Above')\n",
    "                    # print('found ' + column+'Above') #\n",
    "                #below\n",
    "                if formDictFromJson.get(column+'Below', False):\n",
    "                    rowDictionary['below'] = formDictFromJson.get(column+'Below')\n",
    "                    # print('found ' + column+'Below') #\n",
    "                outputDict[column] = rowDictionary #append row with column name as a key\n",
    "            # print(outputDict)\n",
    "            return outputDict\n",
    "        \n",
    "        def queryBuilder(formDictionary):\n",
    "            \n",
    "            def handleBracketsAndLogicalOperators(input, param, like):\n",
    "                if like:\n",
    "                    likePart = ' LIKE '\n",
    "                elif not like:\n",
    "                    likePart = ' NOT LIKE '\n",
    "                splittedResults = re.split(r\" OR | AND \", input) #split on logic operator\n",
    "                phrases = []\n",
    "                for res in splittedResults:\n",
    "                    res = re.sub(r'\\(|\\)', '', res) #remove brackets\n",
    "                    res = re.sub(r'^ +| +$', '', res) #remove spaces at both ends\n",
    "                    phrases.append(res)\n",
    "                for phrase in phrases: #make placeholders one by one\n",
    "                    input = re.sub(phrase, '<<<>>>', input, count=1) #count=1 to only replace the first match. This is needed because phrases content can overlap\n",
    "                for phrase in phrases: #fill placeholders one by one\n",
    "                    input = re.sub('<<<>>>', param + likePart + \"('%\" +phrase+\"%')\", input, count=1) #only first match\n",
    "                return input\n",
    "\n",
    "            querySelectPart = \"SELECT \"\n",
    "            queryMainPart = \"\\nWHERE 1=1\" #removing this later\n",
    "            for columnName in formDictionary.keys():\n",
    "                currentColumnDictionary = formDictionary[columnName].items()\n",
    "                for key, value in currentColumnDictionary:\n",
    "                    # SELECT STATEMENT APPENDING\n",
    "                    if key == 'show' and value:\n",
    "                        querySelectPart += columnName + ', '\n",
    "                    #ABOVE & BELOW \n",
    "                    if key == 'above' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" > '\"+value+\"'\"\n",
    "                    if key == 'below' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" < '\"+value+\"'\"\n",
    "                    #NECESSARY PHRASE\n",
    "                    if key == 'necessary' and value: # if list not empty\n",
    "                        queryMainPart += \"\\nAND \"+ handleBracketsAndLogicalOperators(value, columnName, like=True)\n",
    "                    #FORBIDDEN PHRASE\n",
    "                    if key == \"forbidden\" and value:\n",
    "                        queryMainPart += \"\\nAND \"+ handleBracketsAndLogicalOperators(value, columnName, like=False)\n",
    "            queryMainPart += '\\nORDER BY (salaryMin+SalaryMax)/2 ASC, (JULIANDAY(datetimeLast) - JULIANDAY(datetimeFirst)) * 24 * 60 DESC;' #order by\n",
    "\n",
    "            querySelectPart = re.sub(r\", $\", '', querySelectPart) #remove \", \" from the end\n",
    "            querySelectPart += \" FROM \"+tableName # 1=1 to append only ANDs\n",
    "            queryMainPart = re.sub(r\" 1=1\\nAND\", '', queryMainPart) #remove \"1=1\\nAND\" if at least 1 filter specified\n",
    "            queryMainPart = re.sub(r\"\\nWHERE 1=1\", '', queryMainPart)# or remove WHERE 1=1 if no filters specified. If specified shouldn't match this regexp\n",
    "            query = querySelectPart + queryMainPart\n",
    "            queryPlot = \"SELECT datetimeFirst, datetimeLast, title, salaryMin, salaryMax FROM \"+ tableName + queryMainPart #2nd query - always select datetimes and salaries for plotting, order by time active and avg salary\n",
    "            # print('\\n'+query+'\\n'+queryPlot)\n",
    "            return query, queryPlot\n",
    "        \n",
    "        global dataframeTable #to make it accessible to download at all times\n",
    "        dataframeTable, dataframePlot = queryBuilder(makeFormOutputDictionary())\n",
    "        dataframeTable = database.queryToDataframe(dataframeTable)\n",
    "        dataframePlot = database.queryToDataframe(dataframePlot)\n",
    "\n",
    "        if len(dataframePlot) > 0 and len(dataframeTable) > 0: #tho their lengths should be equal\n",
    "            plot = makeBokehPlot(dataframePlot)\n",
    "            table = makeBokehTable(dataframeTable)\n",
    "            return json.dumps([json_item(plot), json_item(table), int(len(dataframeTable))])\n",
    "\n",
    "        return json.dumps(['noResultsFound']) #when no results return a str\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)#JUPYTER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
