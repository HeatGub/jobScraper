{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a browser and set the cookies from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'functionDone': True,\n",
       " 'message': 'cookies for justjoin.it successfully set'}"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True # recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "\n",
    "# ChromeDriver should match browser version. If outdated download from:\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "def setCookiesFromJson():  \n",
    "    try:\n",
    "        DRIVER.get(BASE_URL) #RUN BROWSER\n",
    "        currentUrlDomain = DRIVER.current_url\n",
    "        currentUrlDomain = re.search(r'^https?://([^/]+)', currentUrlDomain)\n",
    "        currentUrlDomain = currentUrlDomain.group(1)  \n",
    "        currentUrlDomain = re.sub(r'^www\\.', '', currentUrlDomain)\n",
    "        currentUrlDomain = re.sub(r'^\\.', '', currentUrlDomain)\n",
    "        # print(currentUrlDomain)\n",
    "        with open('cookies.json', 'r', newline='') as inputdata:\n",
    "            cookies = json.load(inputdata)\n",
    "            cookiesAdded = 0\n",
    "            for cookie in cookies: #works only after driver.get\n",
    "                if re.match(r\".?\"+currentUrlDomain, cookie['domain']): # can only add cookies for current domain\n",
    "                    DRIVER.add_cookie(cookie)\n",
    "                    cookiesAdded += 1\n",
    "            if cookiesAdded > 0:\n",
    "                DRIVER.refresh() # to load cookies\n",
    "                return {'success':True, 'functionDone':True, 'message':'cookies for ' + currentUrlDomain + ' successfully set'}\n",
    "            elif (cookiesAdded == 0):\n",
    "                return {'success':False, 'functionDone':True, 'message':'no cookies for ' + currentUrlDomain + ' found in cookies.json'}\n",
    "    except Exception as exception:\n",
    "        return {'success':False, 'functionDone':True, 'message':str(exception)} # 'functionDone':True because it's not necessary\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "chrome_options.add_argument(\"window-size=800,1000\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "DRIVER = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "BASE_URL = \"https://justjoin.it/job-offers/bialystok?with-salary=yes\"\n",
    "DRIVER.get(BASE_URL)\n",
    "setCookiesFromJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the URLs from all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 23\n"
     ]
    }
   ],
   "source": [
    "# def offerNotFound():\n",
    "#     try:\n",
    "#         elemnt = DRIVER.find_element(\"xpath\", '/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/p')\n",
    "#         # print(el.get_attribute('data-index'))\n",
    "#         print(elemnt.text)\n",
    "#         if elemnt.text == 'We did not find any offers for the above search criteria.':\n",
    "#             return True\n",
    "#     except:\n",
    "#         return False\n",
    "# offerNotFound()\n",
    "\n",
    "offers_urls = []\n",
    "lastIndexesList = []\n",
    "\n",
    "def anyOffersOnTheList():\n",
    "    try:\n",
    "        content = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-ggjav7')\n",
    "        offersList = content.find_element(By.XPATH, '//*[@data-test-id=\"virtuoso-item-list\"]')\n",
    "        offers = offersList.find_elements(By.XPATH, '//div[@data-index]')\n",
    "        if len(offers) > 0:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "anyOffersOnTheList()\n",
    "\n",
    "def fetchOffersUrlsFromSinglePage():\n",
    "    # offersFound = content.find_element(By.CSS_SELECTOR, '.MuiTypography-root.MuiTypography-subtitle4.css-pmys26')\n",
    "    # print(offersFound.text) # DOESNT MATCH AMOUNT COUNT BY DATA-INDEX\n",
    "    content = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-ggjav7')\n",
    "    offersList = content.find_element(By.XPATH, '//*[@data-test-id=\"virtuoso-item-list\"]')\n",
    "    offers = offersList.find_elements(By.XPATH, '//div[@data-index]') # 30 or 31 offers\n",
    "    for offer in offers:\n",
    "        lastIndexesList.append(offer.get_attribute('data-index'))\n",
    "        hrefElement = offer.find_element(By.XPATH, \".//div/div/a\")\n",
    "        offers_urls.append(hrefElement.get_property(\"href\"))\n",
    "\n",
    "# for i in range(10):\n",
    "fetchOffersUrlsFromSinglePage()\n",
    "DRIVER.execute_script(\"window.scrollBy(0, innerHeight);\")\n",
    "print(lastIndexesList[0], lastIndexesList[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse offer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Salary: 1000 - 1200 PLN/MD + VAT on B2B\n",
      "Remote: 100% remote or hybrid from Warsaw, Tricity or Łódź\n",
      "  Why choose this offer?\n",
      "You can expect a flexible work organization\n",
      "The international work environment will give you the opportunity to interact with the English language on a daily basis\n",
      "Scandinavian organizational culture will provide you with work-life balance, you will gain time for additional training (financed by Jit)\n",
      "The Jit community will bring you a nice time during regular integration meetings\n",
      "  Project\n",
      "The project encompasses the full onboarding of applications and platforms into CyberArk solution, including all stages from integration to password management. The scope involves building custom connection components and password managers, enabling secure and efficient access management across the organization. The goal is to ensure seamless integration of systems with the CyberArk platform, allowing for centralized password and access management while enhancing the overall security of the IT infrastructure.\n",
      "  Expected competences and knowledge\n",
      "Several years of proven experience working with CyberArk or similar PAM solution\n",
      "Experience working as PAM developer developing custom connection components\n",
      "Knowledge of identity security best practices, for both on-premise and cloud environments\n",
      "Knowledge of fundamental security approaches and principles (such as SoD, Least Privilege, Zero Trust)\n",
      "Previous experience working in a DevOps team in Agile/Scrum setup\n",
      "Understanding of IT processes and system development life cycle\n",
      "Familiarity with Cyber Security controls and frameworks (such as CIS, COBIT, NIST, ISO 2700x)\n",
      "The ability to do conversion between business and technical context\n",
      "Fluency in English (spoken and written)\n",
      "  Technologies you'll work with\n",
      "CyberArk\n",
      "PAM\n",
      "Cyber Security frameworks\n",
      "Cloud environment\n",
      "  Client – why choose this particular client from the Jit portfolio?\n",
      "Jit Team has had an over-decade-long relationship with the leading financial group in the Nordic countries, and we are privileged to be our client's premier partner in Poland. At present, over 200 Jit personnel are engaged in the completion of more than 60 projects for this Norwegian major provider of financial services with a global presence and a strong focus on modern technology. Our customer's work atmosphere is epitomized by the Scandinavian culture, which is conducive to people who place emphasis on work-life balance and feedback culture. Furthermore, all projects are executed in international teams, giving constant exposure to the English language. \n",
      "  About Jit Team\n",
      "The Human factor of IT - it's not just a slogan, it's a philosophy. The foundation of Jit Team is people, which is why we prioritise you. We employ over 500 experienced experts. We create highly specialised teams for clients from all over the world. We offer team members developmental projects, a wide range of benefits and a proprietary professional development programme.\n",
      "Behind our maxim are also charitable and educational activities. We support pupils and students by donating learning equipment. We offer internships to help launch careers in IT. We support water rescuers and hospitals by providing the necessary equipment. We are a Polish company and we share what we have achieved over 14 years of activity. By supporting indigenous initiatives, we ensure the circulation of good energy.\n",
      " \n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2024-12-23 10:39:11',\n",
       " '2024-12-23 10:39:11',\n",
       " 'https://justjoin.it/job-offer/jit-team-senior-it-security-consultant-with-pam-bialystok-security',\n",
       " 'Senior IT Security Consultant with PAM',\n",
       " '21 000 - 25 000 PLN\\nNet/month - B2B\\nFull-time | B2B',\n",
       " 21000,\n",
       " 25000,\n",
       " 'Jit Team',\n",
       " 'Remote',\n",
       " 'Senior',\n",
       " '',\n",
       " 'Białystok, +9\\nWarszawa, Aleje Jerozolimskie\\nWrocław, -\\nGdańsk, -\\nGdynia, -\\nKraków, -\\nKatowice, -\\nPoznań, -\\nToruń, -\\nŁódź, -',\n",
       " 'Cybersecurity - Advanced\\nEnglish - Advanced\\nAgile - Regular',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try:\n",
    "#     jobTitle = DRIVER.find_elements(By.CSS_SELECTOR, '.css-sy4ig6')\n",
    "#     print(jobTitle)\n",
    "#     jobTitle = jobTitle.text\n",
    "# except:\n",
    "#     jobTitle = None\n",
    "# print(jobTitle)\n",
    "\n",
    "# singleLocation = https://justjoin.it/job-offer/emagine-polska-technical-architect-warszawa-architecture\n",
    "\n",
    "def getOfferDetails():\n",
    "    # BASIC PARAMETERS WHICH SHOULD ALWAYS BE NOT EMPTY ON THE SITE\n",
    "    try:\n",
    "        offerContent = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-tnvghs')\n",
    "        topContainer = offerContent.find_element(By.CSS_SELECTOR, 'div') # first div 1 level down\n",
    "        topDiv = topContainer.find_element(By.XPATH, \".//*[contains(@class, 'css-10x887j')]\") # .// = as deep as necessary\n",
    "    except Exception as exception:\n",
    "        # print(exception)\n",
    "        return # no point of continuing\n",
    "    try:\n",
    "        jobTitle = topDiv.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "        # print(jobTitle)\n",
    "        employerAndLocationDiv = topDiv.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-yd5zxy') \n",
    "        employer = employerAndLocationDiv.find_element(By.XPATH, './/h2').text # look for h2 as deep as necessary\n",
    "        # print(employer) # name=\"multilocation_button\"\n",
    "    except:\n",
    "        jobTitle, employer = '', ''\n",
    "\n",
    "    try:\n",
    "        location = employerAndLocationDiv.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-mswf74')[1].text # first one is employer\n",
    "        # location = re.sub(r'\\+[0-9]+$', '', location) #remove '+x' where x is int\n",
    "    except:\n",
    "        location = ''\n",
    "    #try clicking for more locations\n",
    "    try:\n",
    "        locationButton = employerAndLocationDiv.find_element(\"xpath\", '//*[@name=\"multilocation_button\"]')\n",
    "        locationButton.click()\n",
    "        locationsMenu = offerContent.find_element(\"xpath\", '//ul[@role=\"menu\"]')\n",
    "        # locationsMenu = locationsMenu.find_elements(By.CSS_SELECTOR, 'li') # 1 level down\n",
    "        location += '\\n' + locationsMenu.text # TEXT EMPTY WHEN MINIMIZED!\n",
    "    except Exception as exception:\n",
    "        pass\n",
    "    # print(location)\n",
    "\n",
    "    #SALARY\n",
    "    try:\n",
    "        salaryAndContract = topContainer.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-1km0bek').text\n",
    "    except:\n",
    "        salaryAndContract= ''\n",
    "\n",
    "    salaryMinAndMax = [None, None] # Nones as these are INTs in DB\n",
    "    if salaryAndContract != '':\n",
    "        try: #to recalculate salary to [PLN/month net]\n",
    "            grossToNetMultiplier = 0.7\n",
    "            hoursPerMonthInFullTimeJob = 168\n",
    "            lines = salaryAndContract.splitlines()[0] # There could be multiple salaries depending on contract type though. It will be in salaryAndContract anyway\n",
    "            splitValues = re.split(r'-', lines) # split on dash for min and max\n",
    "\n",
    "            for i in range(len(splitValues)):\n",
    "                splitValues[i] = splitValues[i].replace(\" \", \"\") # remove spaces\n",
    "                splitValues[i] = re.sub(r\",\\d{1,2}\", '', splitValues[i]) # removes , and /d{1 to 2 occurrences}  (needed when salary as 123,45)\n",
    "                salaryMinAndMax[i] = re.search(r\"\\d+\", splitValues[i]).group() # r = raw, \\d+ = at least 1 digit, group() contains results\n",
    "                \n",
    "            if re.findall(\"brutto\", lines[1]) or re.findall(\"gross\", lines[1]): # gross -> net\n",
    "                salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "                # print(salaryMinAndMax)\n",
    "            if re.findall(\"godz\", lines[1]) or re.findall(\"hr.\", lines[1]): # hr -> month\n",
    "                salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str\n",
    "\n",
    "            salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "        except Exception as exception:\n",
    "            pass    # salaryMinAndMax = [None, None]\n",
    "    # print(salaryMinAndMax)\n",
    "\n",
    "    # print(salaryAndContract)\n",
    "    workModes = ''\n",
    "    positionLevels = ''\n",
    "\n",
    "    try:\n",
    "        fourRectangles = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-snbmy4') # contains just what we need\n",
    "        salaryAndContract += '\\n' + fourRectangles[0].text + ' | ' + fourRectangles[2].text\n",
    "        positionLevels = fourRectangles[1].text\n",
    "        workModes = fourRectangles[3].text\n",
    "    except Exception as exception:\n",
    "        # print(exception)\n",
    "        pass\n",
    "    # print(salaryAndContract)\n",
    "    # print(workModes, positionLevels + '\\n')\n",
    "\n",
    "    #TECHSTACK\n",
    "    techstackExpected, techstackOptional = '', ''\n",
    "    try:\n",
    "        techstackDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[0]\n",
    "        techstackDiv = techstackDiv.find_element(By.CSS_SELECTOR, 'div') # 1 level down\n",
    "        technologies = techstackDiv.find_elements(By.XPATH, './/h4') # look for h4 in all children elements\n",
    "        levels = techstackDiv.find_elements(By.XPATH, './/span') # look for h4 in all children elements\n",
    "        for i in range(len(technologies)):\n",
    "            techWithLvl = technologies[i].text + ' - ' + levels[i].text\n",
    "            # print(techWithLvl)\n",
    "            if levels[i].text == 'Nice To Have': # or levels[i].text == 'Junior'\n",
    "                techstackOptional += '\\n' + techWithLvl\n",
    "            else: # -(nice to have)/junior/regular/advanced/master\n",
    "                techstackExpected += '\\n' + techWithLvl\n",
    "\n",
    "        techstackOptional = re.sub(r\"^\\n\", '', techstackOptional)\n",
    "        techstackExpected = re.sub(r\"^\\n\", '', techstackExpected)\n",
    "    except:\n",
    "        pass # leave empty strs\n",
    "    # print(techstackExpected + '\\n\\n' + techstackOptional)\n",
    "    print('===========================')\n",
    "\n",
    "    # DO THIS NOW\n",
    "    offerValidTo = '' # REMOVE FROM DB?\n",
    "    responsibilities, requirements, optionalRequirements = '', '', '' \n",
    "    try:\n",
    "        descriptionDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[1]\n",
    "        descriptionDiv = descriptionDiv.find_elements(By.XPATH, \"./div\") # 1 level down\n",
    "        print(descriptionDiv[1].text)\n",
    "        # Must have | Nice to have skills: | Responsibilities:\n",
    "        # DODATKOWE INFORMACJE: | WYMAGANIA:\n",
    "        # print(len(descriptionDiv))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(responsibilities, requirements, optionalRequirements)\n",
    "\n",
    "    datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return [datetimeNow, datetimeNow, DRIVER.current_url, jobTitle, salaryAndContract, salaryMinAndMax[0], salaryMinAndMax[1], employer, workModes, positionLevels, offerValidTo, location, techstackExpected, techstackOptional, responsibilities, requirements, optionalRequirements]\n",
    "\n",
    "# driver.get('')\n",
    "\n",
    "getOfferDetails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "strng = ''\n",
    "for i in range (10):\n",
    "    try:\n",
    "        if random.random() > 0.5:\n",
    "            strng += 'a'\n",
    "        else:\n",
    "            strng += 2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(strng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getOfferDetails():\n",
    "#     #JOB TITLE\n",
    "#     try:\n",
    "#         jobTitle = driver.find_element(By.XPATH, '//*[@data-test=\"text-offerTitle\"]') # this element should always exist\n",
    "#         jobTitle = jobTitle.text\n",
    "#     except:\n",
    "#         jobTitle = None\n",
    "    \n",
    "#     #SALARY\n",
    "#     try:\n",
    "#         salaryContainer = driver.find_element(By.XPATH, '//*[@data-test=\"section-contract\"]') # this element should always exist\n",
    "#         salaryAndContract = salaryContainer.text\n",
    "#         # print(salaryAndContract  + '\\n')\n",
    "#     except:\n",
    "#         salaryAndContract = None\n",
    "    \n",
    "#     salaryMinAndMax = [None, None]\n",
    "#     if salaryAndContract:\n",
    "#         try: #to recalculate salary to [PLN/month net] #PLN=only unit on protocol?\n",
    "#             grossToNetMultiplier = 0.7\n",
    "#             hoursPerMonthInFullTimeJob = 168\n",
    "#             lines = salaryAndContract.splitlines()\n",
    "#             if len(lines) >= 3: #should be 2-3 tho\n",
    "#                 lines[0] = lines[0].replace(\" \", \"\") #remove spaces\n",
    "#                 lines[0] = re.sub(r\",\\d{1,2}\", '', lines[0]) #removes dash and /d x(1-2)  (needed when salary as 123,45)\n",
    "#                 salaryMinAndMax = re.findall(r\"\\d+\", lines[0]) #r = raw\n",
    "#                 # print(salaryMinAndMax.split(',', 1)[0])\n",
    "#                 # salaryUnit = re.findall(r\"[^\\d–-]\", lines[0]) #[exclude digits and –/-]\n",
    "#                 # salaryUnit = ''.join(salaryUnit) #join list elements\n",
    "#                 if re.findall(\"brutto\", lines[1]) or re.findall(\"gross\", lines[1]): # gross -> net\n",
    "#                     salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "#                     # print(salaryMinAndMax)\n",
    "#                 if re.findall(\"godz\", lines[1]) or re.findall(\"hr.\", lines[1]): # hr -> month\n",
    "#                     salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str\n",
    "\n",
    "#                 salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "#         except:\n",
    "#             pass    # salaryMinAndMax = [None, None]\n",
    "\n",
    "#     # EMPLOYER\n",
    "#     try:\n",
    "#         employerElement = driver.find_element(\"xpath\", '//*[@data-test=\"anchor-company-link\"]') # this element should always exist\n",
    "#         employer = employerElement.text + ' ' + employerElement.get_property(\"href\")\n",
    "#     except:\n",
    "#         employer = None\n",
    "#     # print(employer  + '\\n')\n",
    "    \n",
    "#     #WORKFROM, EXP, VALIDTO, LOCATION - \"PARAMETERS\"\n",
    "#     workModes, positionLevels, offerValidTo, location = '', '', '', ''\n",
    "#     parametersContainer = driver.find_element(By.CLASS_NAME, \"c21kfgf\")\n",
    "#     parameters = parametersContainer.find_elements(By.CLASS_NAME, \"s1bu9jax\")\n",
    "#     for param in parameters:\n",
    "#         paramType = param.get_attribute(\"data-test\") #element description\n",
    "#         match paramType:\n",
    "#             case \"section-workModes\":\n",
    "#                 workModes = param.text\n",
    "#             case \"section-positionLevels\":\n",
    "#                 positionLevels = param.text\n",
    "#             case \"section-offerValidTo\":\n",
    "#                 offerValidTo = param.text\n",
    "#             case \"section-workplace\":\n",
    "#                 location = param.text\n",
    "#                 try: #to find and click 'more locations' button then fetch what's inside\n",
    "#                     moreLocations = driver.find_element(\"xpath\", '//*[@data-test=\"button-locationPicker\"]')\n",
    "#                     moreLocations.click()\n",
    "#                     # time.sleep(0.05) #probably necessary\n",
    "#                     locations = moreLocations.find_element(\"xpath\", '//*[@data-test=\"modal-locations\"]')\n",
    "#                     location = locations.text\n",
    "#                 except:\n",
    "#                     pass #leave location as it was\n",
    "#     # print(workModes + '\\n\\n' + positionLevels + '\\n\\n' +  offerValidTo + '\\n\\n' +  location + '\\n')\n",
    "\n",
    "#     #TECHSTACK\n",
    "#     descriptionsContainer = driver.find_element(By.CSS_SELECTOR, '#TECHNOLOGY_AND_POSITION')\n",
    "\n",
    "#     techstack = descriptionsContainer.find_elements(By.CLASS_NAME, \"c1fj2x2p\")\n",
    "#     techstackExpected = None\n",
    "#     techstackOptional = None\n",
    "#     for group in techstack:\n",
    "#         if group.text[0:8] == 'EXPECTED' or group.text[0:8] == 'WYMAGANE': # eng/pl same word length\n",
    "#             techstackExpected = group.text[9:]\n",
    "#         elif group.text[0:8] == 'OPTIONAL':\n",
    "#             techstackOptional = group.text[9:]\n",
    "#         elif group.text[0:13] == 'MILE WIDZIANE': # polish version\n",
    "#             techstackOptional = group.text[14:]\n",
    "#     # print(str(techstackExpected) + '\\n\\n' + str(techstackOptional) + '\\n')\n",
    "\n",
    "#     #RESPONSIBILITIES\n",
    "#     try:\n",
    "#         try:\n",
    "#             responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]/ul').text #/only ul elements\n",
    "#         except:\n",
    "#             responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]').text #/if it's a single entry\n",
    "#     except:\n",
    "#         responsibilities = None\n",
    "#         # print('RESPONSIBILITIES:\\n' + str(responsibilities) + '\\n' + driver.current_url)\n",
    "\n",
    "#     #REQUIREMENTS\n",
    "#     try:\n",
    "#         try:\n",
    "#             requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]/ul').text\n",
    "#         except:\n",
    "#             requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]').text #/if it's a single entry\n",
    "#     except:\n",
    "#         requirements = None\n",
    "#         # print('REQUIREMENTS:\\n' + str(requirements) + '\\n' + driver.current_url)\n",
    "\n",
    "\n",
    "#     #OPTIONAL REQUIREMENTS\n",
    "#     try:\n",
    "#         optionalRequirementsContainer = descriptionsContainer.find_elements(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]/li')\n",
    "#         if len(optionalRequirementsContainer) > 0:\n",
    "#             optionalRequirements = ''\n",
    "#             for optionalRequirement in optionalRequirementsContainer:\n",
    "#                 optionalRequirements += optionalRequirement.text + '\\n'\n",
    "#         elif len(optionalRequirementsContainer) <= 0:\n",
    "#             try:\n",
    "#                 optionalRequirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]').text\n",
    "#             except:\n",
    "#                 optionalRequirements = None\n",
    "#                 # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)        \n",
    "#     except:\n",
    "#         optionalRequirements = None\n",
    "#     # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)\n",
    "#     datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     return [datetimeNow, datetimeNow, driver.current_url, jobTitle, salaryAndContract, salaryMinAndMax[0], salaryMinAndMax[1], employer, workModes, positionLevels, offerValidTo, location, techstackExpected, techstackOptional, responsibilities, requirements, optionalRequirements]\n",
    "\n",
    "# driver.get('https://theprotocol.it/szczegoly/praca/mlodszy-specjalista-it-warszawa-nowoursynowska-162j,oferta,f03f0000-5202-f248-4bdc-08dce9bbe033?s=-3293542755&searchId=533dda90-88b7-11ef-942d-5f9061073a19')\n",
    "# getOfferDetails()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(resultsDataFrame.employer)\n",
    "# # resultsDataFrame.to_sql('offers', 'resultsDf.db') #alchemy needed\n",
    "import sqlite3\n",
    "\n",
    "tableName = 'test4' #not needed as an argument\n",
    "\n",
    "class database():\n",
    "    def createTableIfNotExists(): #if not exists\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS \" + tableName + \"\"\" (\n",
    "                    datetimeFirst TEXT,\n",
    "                    datetimeLast TEXT,\n",
    "                    url TEXT,\n",
    "                    title TEXT, \n",
    "                    salaryAndContract TEXT,\n",
    "                    salaryMin INT,\n",
    "                    salaryMax INT,\n",
    "                    employer TEXT,\n",
    "                    workModes TEXT,\n",
    "                    positionLevels TEXT,\n",
    "                    offerValidTo TEXT,\n",
    "                    location TEXT,\n",
    "                    techstackExpected TEXT,\n",
    "                    techstackOptional TEXT,\n",
    "                    responsibilities TEXT,\n",
    "                    requirements TEXT,\n",
    "                    optionalRequirements TEXT);\"\"\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def selectAll():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM\" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def executeQuery(query):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def recordFound(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        # print(urlPartToCompare)\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT datetimeFirst FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if len(result) >0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def insertRecord(dictionary):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"INSERT INTO \" + tableName + \" VALUES (:datetimeFirst, :datetimeLast, :url, :title, :salaryAndContract, :salaryMin, :salaryMax, :employer, :workModes, :positionLevels, :offerValidTo, :location, :techstackExpected, :techstackOptional, :responsibilities, :requirements, :optionalRequirements)\", dictionary)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def updateDatetimeLast(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"UPDATE \" + tableName + \" SET datetimeLast = '\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")) + \"'  WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        # cursor.execute(\"SELECT datetimeLast FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def countAllRecords():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT COUNT (*) FROM \" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        resultTuple = cursor.fetchall()[0]\n",
    "        (count,) = resultTuple #unpacking tuple\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return str(count)\n",
    "\n",
    "    def queryToDataframe(fullQuery):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        # df = pd.read_sql(\"SELECT datetimeFirst, datetimeLast FROM \" +tableName+ \";\", con=connection)\n",
    "        df = pd.read_sql(fullQuery, con=connection)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        # print('\\n'+str(len(cursor.fetchall())) + ' records found')\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return df\n",
    "    \n",
    "database.createTableIfNotExists()\n",
    "database.countAllRecords()\n",
    "# database.executeQuery(\"DROP TABLE\" + tableName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsAll = ['datetimeFirst', 'datetimeLast', 'url', 'title', 'salaryAndContract', 'salaryMin', 'salaryMax', 'employer', 'workModes', 'positionLevels', 'offerValidTo', 'location', 'techstackExpected', 'techstackOptional', 'responsibilities', 'requirements', 'optionalRequirements'] # move out of global scope later\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def scrapToDatabase():\n",
    "    timeDeltas = []\n",
    "    inserts = 0\n",
    "    updates = 0\n",
    "    print(database.countAllRecords() + ' records before run')\n",
    "    for i in range (0,2):\n",
    "    # for i in range (len(offers_urls)):\n",
    "        driver.get(offers_urls[i])\n",
    "        if not offerNotFound():\n",
    "            resultsList = getOfferDetails()\n",
    "            outputDictionary = {}\n",
    "            for column, offerDetail in zip(columnsAll, resultsList):\n",
    "                outputDictionary[column] = offerDetail #combine 2 lists into 1 dictionary\n",
    "            # before = time.time()\n",
    "            if database.recordFound(driver.current_url):\n",
    "                database.updateDatetimeLast(driver.current_url)\n",
    "                # print(driver.current_url)\n",
    "                updates += 1\n",
    "            else:\n",
    "                database.insertRecord(outputDictionary) # insert into databas\n",
    "                inserts += 1\n",
    "                # print('insert')\n",
    "            # timeDeltas.append(time.time() - before)\n",
    "            #ending here and starting in an above for/zip loop it takes ~(1/100)s - good enough\n",
    "            print (str(i+1) + '/' + str(len(offers_urls)) + ' done')\n",
    "        else:\n",
    "            print('OFFER NOT FOUND: ' +  driver.current_url)\n",
    "        time.sleep(random.uniform(0.35,0.85)) #Humanize requests frequency\n",
    "    # print(np.mean(timeDeltas))\n",
    "    print(str(inserts) + ' inserts | ' + str(updates) + ' updates')\n",
    "\n",
    "scrapToDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, send_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.models.widgets import DataTable, TableColumn\n",
    "from bokeh.models import ColumnDataSource, WheelZoomTool, HTMLTemplateFormatter, HoverTool, TapTool, Range1d, LinearAxis\n",
    "from bokeh.embed import json_item\n",
    "from bokeh.io import curdoc #for dark theme\n",
    "import io #for a csv buffer\n",
    "\n",
    "def makeBokehPlot(dataframe): #Only offers with specified salary?\n",
    "    # len(dataframe) >=1 at this point \n",
    "    # dataframe already ordered by (salaryMin+SalaryMax)/2 ASC\n",
    "\n",
    "    pd.options.mode.copy_on_write = True #recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "    nonNanRowsDf = dataframe[dataframe['salaryMin'].notna()]\n",
    "    nanRowsDf = dataframe[dataframe['salaryMin'].isna()]\n",
    "\n",
    "    # SPECIFY UNSPECIFIED BARS HEIGHT\n",
    "    if len(nonNanRowsDf) > 0: #otherwise division by 0 possible\n",
    "        lookUpToValues = 2 #how many values to count average\n",
    "        avgOfNLowestMinSalaries = nonNanRowsDf['salaryMin'].head(lookUpToValues).tolist() #select up to 2 values\n",
    "        avgOfNLowestMinSalaries = sum(avgOfNLowestMinSalaries) / len(avgOfNLowestMinSalaries) #avg\n",
    "        avgOfNLowestMaxSalaries = nonNanRowsDf['salaryMax'].head(lookUpToValues).tolist() #select up to 2 values\n",
    "        avgOfNLowestMaxSalaries = sum(avgOfNLowestMaxSalaries) / len(avgOfNLowestMaxSalaries) #avg\n",
    "        nanRowsDf['salaryMin'] = nanRowsDf['salaryMin'].fillna(avgOfNLowestMinSalaries) #replace nulls with values\n",
    "        nanRowsDf['salaryMax'] = nanRowsDf['salaryMax'].fillna(avgOfNLowestMaxSalaries)\n",
    "    else: #if only unspecified salaries foud\n",
    "        avgOfNLowestMinSalaries = 4200 #some value to plot\n",
    "        avgOfNLowestMaxSalaries = 4200\n",
    "        nanRowsDf['salaryMin'] = nanRowsDf['salaryMin'].fillna(avgOfNLowestMinSalaries) #replace nulls with values\n",
    "        nanRowsDf['salaryMax'] = nanRowsDf['salaryMax'].fillna(avgOfNLowestMaxSalaries)\n",
    "        \n",
    "    dataSalaryUnspecified = {\n",
    "        'x': nanRowsDf.index.tolist(),\n",
    "        'title': nanRowsDf['title'].values.tolist(),\n",
    "        'activeFor': [(dtstr.days) for dtstr in (pd.to_datetime(nanRowsDf[\"datetimeLast\"])-pd.to_datetime(nanRowsDf[\"datetimeFirst\"])).tolist()], #.days shows only days\n",
    "        'salaryAvg': [((avgOfNLowestMinSalaries+avgOfNLowestMaxSalaries)/2) for i in range (len(nanRowsDf))]\n",
    "    }\n",
    "    dataSalarySpecified = {\n",
    "        'x': nonNanRowsDf.index.tolist(),\n",
    "        'title': nonNanRowsDf['title'].values.tolist(),\n",
    "        'activeFor': [(dtstr.days) for dtstr in (pd.to_datetime(nonNanRowsDf[\"datetimeLast\"])-pd.to_datetime(nonNanRowsDf[\"datetimeFirst\"])).tolist()], #.days shows only days\n",
    "        'salaryMin': nonNanRowsDf['salaryMin'].values.tolist(),\n",
    "        'salaryMax': nonNanRowsDf['salaryMax'].values.tolist(),\n",
    "        'salaryAvg': [(a + b) / 2 for a, b in zip(nonNanRowsDf['salaryMin'].values.tolist(), nonNanRowsDf['salaryMax'].values.tolist())],\n",
    "    }\n",
    "\n",
    "    #Calculate ranges - SAFE MAX by declaring default values used if empty list\n",
    "    maxActiveFor = int(max(max(dataSalaryUnspecified['activeFor'], default=0) , max(dataSalarySpecified['activeFor'], default=0))) +1 #\n",
    "    maxSalary = max(max(dataSalaryUnspecified['salaryAvg'], default=0) , max(dataSalarySpecified['salaryMax'], default=0)) * 1.05\n",
    "\n",
    "    sourceSalaryUnspecified = ColumnDataSource(dataSalaryUnspecified) #2 data sources\n",
    "    sourceSalarySpecified = ColumnDataSource(dataSalarySpecified) #2 data sources\n",
    "    plot = figure(title=\"\", x_axis_label='Offer index', y_axis_label='Salary', height = 400, sizing_mode='stretch_width')\n",
    "    plot.y_range = Range1d(start=0 - 1, end=maxSalary) # * 1.2 to fit the bars\n",
    "    plot.x_range = Range1d(start=0 - 1, end=int(len(dataframe))) #too much empty space by default\n",
    "    plot.extra_y_ranges = {\"y2\": Range1d(start=0, end=maxActiveFor)} #add 1 day\n",
    "    #COLORS\n",
    "    salaryUnspecifiedColor = 'rgb(60,60,160)'\n",
    "    salarySpecifiedColor = 'rgb(80,80,220)'\n",
    "    # daysActiveColor = 'rgb(30,150,30)'\n",
    "    daysActiveColor = 'rgb(60,100,40)'\n",
    "    # SALARY UNSPECIFIED BARS\n",
    "    plot.vbar('x', top = 'salaryAvg', width = 0.70, source = sourceSalaryUnspecified, color=salaryUnspecifiedColor, alpha = 1) # MAIN BAR\n",
    "    plot.vbar('x', top = 'activeFor', y_range_name=\"y2\", source = sourceSalaryUnspecified, color=daysActiveColor, alpha = 0.15, width=0.90) # Active for\n",
    "    # plot.segment(x0='x', y0='salaryMin', x1='x', y1='salaryMax', source=sourceSalaryUnspecified, line_width=2, color='black', alpha = 0.5) #Error bar\n",
    "    # SALARY SPECIFIED BARS\n",
    "    plot.vbar('x', top = 'salaryAvg', width = 0.70, source = sourceSalarySpecified, color=salarySpecifiedColor, alpha = 1) # MAIN BAR\n",
    "    plot.vbar('x', top = 'activeFor', y_range_name=\"y2\", source = sourceSalarySpecified, color=daysActiveColor, alpha = 0.15, width=0.90) # Active for\n",
    "    plot.segment(x0='x', y0='salaryMin', x1='x', y1='salaryMax', source=sourceSalarySpecified, line_width=1.5, color='black', alpha=0.75) #Error bar\n",
    "    \n",
    "    plot.add_layout(LinearAxis(y_range_name=\"y2\", axis_label=\"Days adtive\"), 'right') # Add the second y-axis to the right\n",
    "    \n",
    "    # Configure minor gridlines\n",
    "    plot.xgrid.minor_grid_line_color = 'rgb(80,80,80)'\n",
    "    plot.ygrid.minor_grid_line_color = 'rgb(80,80,80)'\n",
    "    plot.xgrid.minor_grid_line_alpha = 0.5 # Opacity\n",
    "    plot.ygrid.minor_grid_line_alpha = 0.5\n",
    "\n",
    "    taptool = TapTool() #highlight on tap\n",
    "    wheel_zoom = WheelZoomTool()\n",
    "    plot.toolbar.active_scroll = wheel_zoom\n",
    "    hoverSalaryUnpecified = HoverTool(tooltips=[(\"Offer index:\", \"@x\"), (\"Job title:\", \"@title\"), (\"Salary:\", \"Unspecified\"), (\"Active for:\", \"@activeFor days\")])\n",
    "    hoverSalaryUnpecified.renderers = [plot.renderers[0]]# hover tool only on the salary bars\n",
    "    hoverSalarySpecified = HoverTool(tooltips=[(\"Offer index:\", \"@x\"), (\"Job title:\", \"@title\"), (\"Min/Avg/Max:\", \"@salaryMin{0.}/@salaryAvg{0.}/@salaryMax{0.}\"), (\"Active for:\", \"@activeFor days\")]) #{0} = no decimals\n",
    "    hoverSalarySpecified.renderers = [plot.renderers[2]]# hover tool only on the salary bars\n",
    "    plot.add_tools(hoverSalarySpecified, hoverSalaryUnpecified, taptool) #wheel_zoom removed for now\n",
    "    #DARK THEME\n",
    "    curdoc().theme = 'dark_minimal'\n",
    "    curdoc().add_root(plot) #to apply the theme\n",
    "    return plot\n",
    "\n",
    "def makeBokehTable(dataframe):\n",
    "    source = ColumnDataSource(dataframe)\n",
    "    columns = []\n",
    "    for column in dataframe.columns:\n",
    "        if column == 'url': # to make a hyperlink\n",
    "            columns.append(TableColumn(field=column, title=column, formatter=HTMLTemplateFormatter(template=\"\"\"<a href=\"<%= value %>\" target=\"_blank\"><%= value %></a>\"\"\")))\n",
    "        else:\n",
    "            columns.append(TableColumn(field=column, title=column))     \n",
    "    table = DataTable(source=source, columns=columns, height = 800, editable=True, sizing_mode=\"stretch_width\")\n",
    "    return table\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/downloadCsv')\n",
    "def downloadCsv():\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csvName = \"jobScrappingResults \" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")) + \".csv\"\n",
    "    # Save the DataFrame to a CSV in memory\n",
    "    buffer = io.BytesIO() #buffer for a csv file to avoid saving csv on a disk\n",
    "    dataframeTable.to_csv(buffer, sep=',', encoding='utf-8-sig', index=True, header=True)\n",
    "    buffer.seek(0)  # Reset buffer position to the beginning\n",
    "    # Send the CSV file as a downloadable response\n",
    "    return send_file(buffer, as_attachment=True, download_name=csvName, mimetype='text/csv')\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def form():\n",
    "    if request.method == 'GET':\n",
    "        # return render_template(\"form.html\", columnsAll=columnsAll)\n",
    "        return render_template(\"app.html\", columnsAll=columnsAll, resources=CDN.render())\n",
    "    \n",
    "    elif request.method == 'POST':\n",
    "        def makeFormOutputDictionary():\n",
    "            formDictFromJson = request.get_json() #get form values from a request\n",
    "            outputDict = {}\n",
    "            for column in columnsAll:\n",
    "                rowDictionary = {'show': False, 'necessary': None, 'forbidden': None, 'above': None, 'below': None}\n",
    "                #show column\n",
    "                if formDictFromJson.get(column+'Show', False): #if not found assign False. Found only if form field not empty\n",
    "                    rowDictionary['show'] = True\n",
    "                #necessary phrase\n",
    "                if formDictFromJson.get(column+'Necessary', False):\n",
    "                    phraseNecessary = formDictFromJson.get(column+'Necessary')\n",
    "                    # phraseNecessary = phraseNecessary.split(\", \") #delete\n",
    "                    rowDictionary['necessary'] = phraseNecessary\n",
    "                #forbidden phrase\n",
    "                if formDictFromJson.get(column+'Forbidden', False):\n",
    "                    phraseForbidden = formDictFromJson.get(column+'Forbidden')\n",
    "                    # phraseForbidden = phraseForbidden.split(\", \") #delete\n",
    "                    rowDictionary['forbidden'] = phraseForbidden\n",
    "                #above\n",
    "                if formDictFromJson.get(column+'Above', False):\n",
    "                    rowDictionary['above'] = formDictFromJson.get(column+'Above')\n",
    "                    # print('found ' + column+'Above') #\n",
    "                #below\n",
    "                if formDictFromJson.get(column+'Below', False):\n",
    "                    rowDictionary['below'] = formDictFromJson.get(column+'Below')\n",
    "                    # print('found ' + column+'Below') #\n",
    "                outputDict[column] = rowDictionary #append row with column name as a key\n",
    "            # print(outputDict)\n",
    "            return outputDict\n",
    "        \n",
    "        def queryBuilder(formDictionary):\n",
    "            \n",
    "            def handleBracketsAndLogicalOperators(input, param, like):\n",
    "                if like:\n",
    "                    likePart = ' LIKE '\n",
    "                elif not like:\n",
    "                    likePart = ' NOT LIKE '\n",
    "                splittedResults = re.split(r\" OR | AND \", input) #split on logic operator\n",
    "                phrases = []\n",
    "                for res in splittedResults:\n",
    "                    res = re.sub(r'\\(|\\)', '', res) #remove brackets\n",
    "                    res = re.sub(r'^ +| +$', '', res) #remove spaces at both ends\n",
    "                    phrases.append(res)\n",
    "                for phrase in phrases: #make placeholders one by one\n",
    "                    input = re.sub(phrase, '<<<>>>', input, count=1) #count=1 to only replace the first match. This is needed because phrases content can overlap\n",
    "                for phrase in phrases: #fill placeholders one by one\n",
    "                    input = re.sub('<<<>>>', param + likePart + \"('%\" +phrase+\"%')\", input, count=1) #only first match\n",
    "                return input\n",
    "\n",
    "            querySelectPart = \"SELECT \"\n",
    "            queryMainPart = \"\\nWHERE 1=1\" #removing this later\n",
    "            for columnName in formDictionary.keys():\n",
    "                currentColumnDictionary = formDictionary[columnName].items()\n",
    "                for key, value in currentColumnDictionary:\n",
    "                    # SELECT STATEMENT APPENDING\n",
    "                    if key == 'show' and value:\n",
    "                        querySelectPart += columnName + ', '\n",
    "                    #ABOVE & BELOW \n",
    "                    if key == 'above' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" > '\"+value+\"'\"\n",
    "                    if key == 'below' and value:\n",
    "                        queryMainPart += \"\\nAND \"+columnName+\" < '\"+value+\"'\"\n",
    "                    #NECESSARY PHRASE\n",
    "                    if key == 'necessary' and value: # if list not empty\n",
    "                        queryMainPart += \"\\nAND \"+ handleBracketsAndLogicalOperators(value, columnName, like=True)\n",
    "                    #FORBIDDEN PHRASE\n",
    "                    if key == \"forbidden\" and value:\n",
    "                        queryMainPart += \"\\nAND \"+ handleBracketsAndLogicalOperators(value, columnName, like=False)\n",
    "            queryMainPart += '\\nORDER BY (salaryMin+SalaryMax)/2 ASC, (JULIANDAY(datetimeLast) - JULIANDAY(datetimeFirst)) * 24 * 60 DESC;' #order by\n",
    "\n",
    "            querySelectPart = re.sub(r\", $\", '', querySelectPart) #remove \", \" from the end\n",
    "            querySelectPart += \" FROM \"+tableName # 1=1 to append only ANDs\n",
    "            queryMainPart = re.sub(r\" 1=1\\nAND\", '', queryMainPart) #remove \"1=1\\nAND\" if at least 1 filter specified\n",
    "            queryMainPart = re.sub(r\"\\nWHERE 1=1\", '', queryMainPart)# or remove WHERE 1=1 if no filters specified. If specified shouldn't match this regexp\n",
    "            query = querySelectPart + queryMainPart\n",
    "            queryPlot = \"SELECT datetimeFirst, datetimeLast, title, salaryMin, salaryMax FROM \"+ tableName + queryMainPart #2nd query - always select datetimes and salaries for plotting, order by time active and avg salary\n",
    "            # print('\\n'+query+'\\n'+queryPlot)\n",
    "            return query, queryPlot\n",
    "        \n",
    "        global dataframeTable #to make it accessible to download at all times\n",
    "        dataframeTable, dataframePlot = queryBuilder(makeFormOutputDictionary())\n",
    "        dataframeTable = database.queryToDataframe(dataframeTable)\n",
    "        dataframePlot = database.queryToDataframe(dataframePlot)\n",
    "\n",
    "        if len(dataframePlot) > 0 and len(dataframeTable) > 0: #tho their lengths should be equal\n",
    "            plot = makeBokehPlot(dataframePlot)\n",
    "            table = makeBokehTable(dataframeTable)\n",
    "            return json.dumps([json_item(plot), json_item(table), int(len(dataframeTable))])\n",
    "\n",
    "        return json.dumps(['noResultsFound']) #when no results return a str\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)#JUPYTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strr = \"theprotocol.it\"\n",
    "print(re.match(r\".?\"+strr, \".theprotocol.it\")) # is r\"(www)?.?\" too much?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
