{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a browser and set the cookies from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "\n",
    "def setCookiesFromJson():\n",
    "    with open('cookies.json', 'r', newline='') as inputdata:\n",
    "        cookies = json.load(inputdata)\n",
    "    for cookie in cookies: #works only after driver.get\n",
    "        driver.add_cookie(cookie)\n",
    "    driver.refresh() # to load cookies\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# base_url = \"https://theprotocol.it/filtry/python;t/ai-ml;sp\"\n",
    "# base_url = \"https://theprotocol.it/filtry/python;t/ai-ml;sp/bialystok;wp\"\n",
    "base_url = \"https://theprotocol.it/filtry/sql,python,javascript;t/junior,trainee,assistant;p\"\n",
    "# base_url = \"https://theprotocol.it/filtry/helpdesk;sp/warszawa,bialystok;wp/zdalna,hybrydowa,stacjonarna;rw/\"\n",
    "# base_url = \"https://theprotocol.it/filtry/trainee,assistant,junior;p\"\n",
    "driver.get(base_url)\n",
    "setCookiesFromJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the URLs from all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 urls fetched\n",
      "page 2 urls fetched\n",
      "page 3 urls fetched\n",
      "fetched 148 offer urls in total\n"
     ]
    }
   ],
   "source": [
    "def anyOffersOnTheList():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '#main-offers-listing > div.hfenof > div.t2re51w > div')\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "offers_urls = []\n",
    "\n",
    "def fetchOffersUrlsFromSinglePage():\n",
    "    offersContainer = driver.find_element(\"xpath\", '//*[@id=\"main-offers-listing\"]/div[1]/div')\n",
    "    offers = offersContainer.find_elements(By.CLASS_NAME, 'a4pzt2q ')\n",
    "    # offers = offersContainer.find_elements(By.CSS_SELECTOR, '#offer-title') #also works\n",
    "    # print('\\t'+ str(len(offers)) + ' offers:')\n",
    "    for offer in offers:\n",
    "        offers_urls.append(offer.get_property(\"href\"))\n",
    "\n",
    "page = 1 #theprotocol enumerates pages starting from 1\n",
    "while True: # because not sure how many pages are there\n",
    "    site = driver.get(base_url + \"?pageNumber=\" + str(page))\n",
    "    if not anyOffersOnTheList():\n",
    "        print('fetched ' + str(len(offers_urls)) + ' offer urls in total')\n",
    "        break # break if no results\n",
    "    else:\n",
    "        time.sleep(random.uniform(0.5, 1)) #humanize\n",
    "        fetchOffersUrlsFromSinglePage()\n",
    "        print('page ' + str(page) + ' urls fetched')\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offerNotFound():\n",
    "    try:\n",
    "        driver.find_element(\"xpath\", '//*[@data-test=\"text-offerNotFound\"]')\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def getOfferDetails():\n",
    "    #JOB TITLE\n",
    "    try:\n",
    "        jobTitle = driver.find_element(By.XPATH, '//*[@data-test=\"text-offerTitle\"]') # this element should always exist\n",
    "        jobTitle = jobTitle.text\n",
    "    except:\n",
    "        jobTitle = None\n",
    "    \n",
    "    #SALARY\n",
    "    try:\n",
    "        salaryContainer = driver.find_element(By.XPATH, '//*[@data-test=\"section-contract\"]') # this element should always exist\n",
    "        salaryAndContract = salaryContainer.text\n",
    "        # print(salaryAndContract  + '\\n')\n",
    "    except:\n",
    "        salaryAndContract = None\n",
    "    \n",
    "    salaryMinAndMax = [None, None]\n",
    "    if salaryAndContract:\n",
    "        try: #to recalculate salary to [PLN/month net] #PLN=only unit on protocol?\n",
    "            grossToNetMultiplier = 0.7\n",
    "            hoursPerMonthInFullTimeJob = 168\n",
    "            lines = salaryAndContract.splitlines()\n",
    "            if len(lines) >= 3: #should be 2-3 tho\n",
    "                lines[0] = lines[0].replace(\" \", \"\") #remove spaces\n",
    "                salaryMinAndMax = re.findall(r\"\\d+\", lines[0]) #r = raw\n",
    "                # salaryUnit = re.findall(r\"[^\\d–-]\", lines[0]) #[exclude digits and –/-]\n",
    "                # salaryUnit = ''.join(salaryUnit) #join list elements\n",
    "                if re.findall(\"brutto\", lines[1]) or re.findall(\"gross\", lines[1]): # gross -> net\n",
    "                    salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "                if re.findall(\"godz\", lines[1]) or re.findall(\"hr.\", lines[1]): # hr -> month\n",
    "                    salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str \n",
    "                salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "        except:\n",
    "            pass    # salaryMinAndMax = [None, None]\n",
    "\n",
    "    # EMPLOYER\n",
    "    try:\n",
    "        employerElement = driver.find_element(\"xpath\", '//*[@data-test=\"anchor-company-link\"]') # this element should always exist\n",
    "        employer = employerElement.text + ' ' + employerElement.get_property(\"href\")\n",
    "    except:\n",
    "        employer = None\n",
    "    # print(employer  + '\\n')\n",
    "    \n",
    "    #WORKFROM, EXP, VALIDTO, LOCATION - \"PARAMETERS\"\n",
    "    workModes, positionLevels, offerValidTo, location = '', '', '', ''\n",
    "    parametersContainer = driver.find_element(By.CLASS_NAME, \"c21kfgf\")\n",
    "    parameters = parametersContainer.find_elements(By.CLASS_NAME, \"s1bu9jax\")\n",
    "    for param in parameters:\n",
    "        paramType = param.get_attribute(\"data-test\") #element description\n",
    "        match paramType:\n",
    "            case \"section-workModes\":\n",
    "                workModes = param.text\n",
    "            case \"section-positionLevels\":\n",
    "                positionLevels = param.text\n",
    "            case \"section-offerValidTo\":\n",
    "                offerValidTo = param.text\n",
    "            case \"section-workplace\":\n",
    "                location = param.text\n",
    "                try: #to find and click 'more locations' button then fetch what's inside\n",
    "                    moreLocations = driver.find_element(\"xpath\", '//*[@data-test=\"button-locationPicker\"]')\n",
    "                    moreLocations.click()\n",
    "                    # time.sleep(0.05) #probably necessary\n",
    "                    locations = moreLocations.find_element(\"xpath\", '//*[@data-test=\"modal-locations\"]')\n",
    "                    location = locations.text\n",
    "                except:\n",
    "                    pass #leave location as it was\n",
    "    # print(workModes + '\\n\\n' + positionLevels + '\\n\\n' +  offerValidTo + '\\n\\n' +  location + '\\n')\n",
    "\n",
    "    # # # TECHSTACK\n",
    "    descriptionsContainer = driver.find_element(By.CSS_SELECTOR, '#TECHNOLOGY_AND_POSITION')\n",
    "\n",
    "    techstack = descriptionsContainer.find_elements(By.CLASS_NAME, \"c1fj2x2p\")\n",
    "    techstackExpected = None\n",
    "    techstackOptional = None\n",
    "    for group in techstack:\n",
    "        if group.text[0:8] == 'EXPECTED' or group.text[0:8] == 'WYMAGANE':\n",
    "            techstackExpected = group.text[9:]\n",
    "        elif group.text[0:8] == 'OPTIONAL': #never saw polish version yet\n",
    "            techstackOptional = group.text[9:]\n",
    "    # print(techstackExpected + '\\n\\n' + techstackOptional + '\\n')\n",
    "\n",
    "    #RESPONSIBILITIES\n",
    "    try:\n",
    "        try:\n",
    "            responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]/ul').text #/only ul elements\n",
    "        except:\n",
    "            responsibilities = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-responsibilities\"]').text #/if it's a single entry\n",
    "    except:\n",
    "        responsibilities = None\n",
    "        # print('RESPONSIBILITIES:\\n' + str(responsibilities) + '\\n' + driver.current_url)\n",
    "\n",
    "    #REQUIREMENTS\n",
    "    try:\n",
    "        try:\n",
    "            requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]/ul').text\n",
    "        except:\n",
    "            requirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements\"]').text #/if it's a single entry\n",
    "    except:\n",
    "        requirements = None\n",
    "        # print('REQUIREMENTS:\\n' + str(requirements) + '\\n' + driver.current_url)\n",
    "\n",
    "\n",
    "    #OPTIONAL REQUIREMENTS\n",
    "    try:\n",
    "        optionalRequirementsContainer = descriptionsContainer.find_elements(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]/li')\n",
    "        if len(optionalRequirementsContainer) > 0:\n",
    "            optionalRequirements = ''\n",
    "            for optionalRequirement in optionalRequirementsContainer:\n",
    "                optionalRequirements += optionalRequirement.text + '\\n'\n",
    "        elif len(optionalRequirementsContainer) <= 0:\n",
    "            try:\n",
    "                optionalRequirements = descriptionsContainer.find_element(\"xpath\", '//*[@data-test=\"section-requirements-optional\"]').text\n",
    "            except:\n",
    "                optionalRequirements = None\n",
    "                # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)        \n",
    "    except:\n",
    "        optionalRequirements = None\n",
    "    # print('OPTIONAL:\\n' + str(optionalRequirements) + '\\n' + driver.current_url)\n",
    "    datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return [datetimeNow, datetimeNow, driver.current_url, jobTitle, salaryAndContract, salaryMinAndMax[0], salaryMinAndMax[1], employer, workModes, positionLevels, offerValidTo, location, techstackExpected, techstackOptional, responsibilities, requirements, optionalRequirements]\n",
    "\n",
    "# driver.get('https://theprotocol.it/szczegoly/praca/internship---tv-apps-and-services-intern-warszawa-plac-europejski-1,oferta,1a840000-f5ea-0ac0-4543-08dcce51a597?s=8321028996&searchId=a5384d80-770f-11ef-a8ea-4bb4c8c16093')\n",
    "# getOfferDetails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results to dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['datetime', 'url', 'title', 'salaryAndContract', salaryMin, salaryMax, 'employer', 'workModes', 'positionLevels', 'offerValidTo', 'location', 'techstackExpected', 'techstackOptional', 'responsibilities', 'requirements', 'optionalRequirements']\n",
    "# resultsDataFrame = pd.DataFrame([], columns = columns) #create dataframe with columns only\n",
    "\n",
    "# # for i in range (len(offers_urls)):\n",
    "# for i in range (5,6):\n",
    "#     driver.get(offers_urls[i])\n",
    "#     if not offerNotFound():\n",
    "#         resultsDataFrame.loc[len(resultsDataFrame.index)] = getOfferDetails() #append new row\n",
    "#         print (str(i+1) + '/' + str(len(offers_urls)) + ' done')\n",
    "#     else:\n",
    "#         print('OFFER NOT FOUND: ' +  driver.current_url)\n",
    "#     time.sleep(random.uniform(0.25,0.75)) #Humanize requests frequency\n",
    "\n",
    "# # resultsDataFrame.to_csv('results.csv', sep=',', encoding='utf-8-sig', index=True, header=True) #export to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT datetimeLast, techstackExpected FROM test4 WHERE 1=1\n",
      "AND (JULIANDAY(strftime('%Y-%m-%d %H:%M:%S', DATETIME('now', 'localtime'))) - JULIANDAY(datetimeLast)) * 24 < 24\n",
      "AND (techstackExpected LIKE ('%SQL%') OR requirements LIKE ('%SQL%'))\n",
      "AND techstackExpected NOT LIKE ('%javascript%') AND requirements NOT LIKE ('%javascript%')\n",
      "AND techstackExpected NOT LIKE ('%c++%') AND requirements NOT LIKE ('%c++%');\n",
      "\n",
      "61 records found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'171'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(resultsDataFrame.employer)\n",
    "# # resultsDataFrame.to_sql('offers', 'resultsDf.db') #alchemy needed\n",
    "import sqlite3\n",
    "\n",
    "tableName = 'test4' #not needed as an argument\n",
    "\n",
    "class database():\n",
    "    def createTableIfNotExists(): #if not exists\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS \" + tableName + \"\"\" (\n",
    "                    datetimeFirst TEXT,\n",
    "                    datetimeLast TEXT,\n",
    "                    url TEXT,\n",
    "                    title TEXT, \n",
    "                    salaryAndContract TEXT,\n",
    "                    salaryMin INT,\n",
    "                    salaryMax INT,\n",
    "                    employer TEXT,\n",
    "                    workModes TEXT,\n",
    "                    positionLevels TEXT,\n",
    "                    offerValidTo TEXT,\n",
    "                    location TEXT,\n",
    "                    techstackExpected TEXT,\n",
    "                    techstackOptional TEXT,\n",
    "                    responsibilities TEXT,\n",
    "                    requirements TEXT,\n",
    "                    optionalRequirements TEXT);\"\"\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def selectAll():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM\" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def executeQuery(query):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def recordFound(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        # print(urlPartToCompare)\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT datetimeFirst FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if len(result) >0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def insertRecord(dictionary):\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"INSERT INTO \" + tableName + \" VALUES (:datetimeFirst, :datetimeLast, :url, :title, :salaryAndContract, :salaryMin, :salaryMax, :employer, :workModes, :positionLevels, :offerValidTo, :location, :techstackExpected, :techstackOptional, :responsibilities, :requirements, :optionalRequirements)\", dictionary)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    def updateDatetimeLast(url):\n",
    "        urlPartToCompare = re.split(\"[?]s=\", url)[0] #split on '?s=' because after that it's only session related stuff. If no pattern found url unchanged\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"UPDATE \" + tableName + \" SET datetimeLast = '\" + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")) + \"'  WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        # cursor.execute(\"SELECT datetimeLast FROM \" + tableName + \" WHERE url LIKE ('%\" + urlPartToCompare + \"%');\")\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "    def countAllRecords():\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT COUNT (*) FROM \" + tableName +\";\")\n",
    "        connection.commit()\n",
    "        resultTuple = cursor.fetchall()[0]\n",
    "        (count,) = resultTuple #unpacking tuple\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return str(count)\n",
    "\n",
    "    def queryBuilder(onlyLastSeenLessThan24hAgo, keywordsNecessary, keywordsUnacceptable): #keywords lists\n",
    "        connection = sqlite3.connect('results.db')\n",
    "        cursor = connection.cursor()\n",
    "        fullQuery = \"SELECT datetimeLast, techstackExpected FROM \" + tableName + \" WHERE 1=1\" #Includes WHERE to always append a line starting with AND\n",
    "        if onlyLastSeenLessThan24hAgo:\n",
    "            fullQuery += \"\\nAND (JULIANDAY(strftime('%Y-%m-%d %H:%M:%S', DATETIME('now', 'localtime'))) - JULIANDAY(datetimeLast)) * 24 < 24\" \n",
    "        if keywordsNecessary:\n",
    "            for keyword in keywordsNecessary:\n",
    "                fullQuery += \"\\nAND (techstackExpected LIKE ('%\"+keyword+\"%') OR requirements LIKE ('%\"+keyword+\"%'))\"\n",
    "        if keywordsUnacceptable:\n",
    "            for keyword in keywordsUnacceptable:\n",
    "                fullQuery += \"\\nAND techstackExpected NOT LIKE ('%\"+keyword+\"%') AND requirements NOT LIKE ('%\"+keyword+\"%')\"\n",
    "        fullQuery += ';'\n",
    "        print(fullQuery)\n",
    "        cursor.execute(fullQuery)\n",
    "        connection.commit()\n",
    "        # print(cursor.fetchall())\n",
    "        print('\\n'+str(len(cursor.fetchall())) + ' records found')\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    \n",
    "database.createTableIfNotExists()\n",
    "database.queryBuilder(True, ['SQL'], ['javascript', 'c++'])\n",
    "database.countAllRecords()\n",
    "# database.executeQuery(\"DROP TABLE\" + tableName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 records before run\n",
      "1/148 done\n",
      "2/148 done\n",
      "3/148 done\n",
      "4/148 done\n",
      "5/148 done\n",
      "6/148 done\n",
      "7/148 done\n",
      "8/148 done\n",
      "9/148 done\n",
      "10/148 done\n",
      "11/148 done\n",
      "12/148 done\n",
      "13/148 done\n",
      "14/148 done\n",
      "15/148 done\n",
      "16/148 done\n",
      "17/148 done\n",
      "18/148 done\n",
      "19/148 done\n",
      "20/148 done\n",
      "21/148 done\n",
      "22/148 done\n",
      "23/148 done\n",
      "24/148 done\n",
      "25/148 done\n",
      "26/148 done\n",
      "27/148 done\n",
      "28/148 done\n",
      "29/148 done\n",
      "30/148 done\n",
      "31/148 done\n",
      "32/148 done\n",
      "33/148 done\n",
      "34/148 done\n",
      "35/148 done\n",
      "36/148 done\n",
      "37/148 done\n",
      "38/148 done\n",
      "39/148 done\n",
      "40/148 done\n",
      "41/148 done\n",
      "42/148 done\n",
      "43/148 done\n",
      "44/148 done\n",
      "45/148 done\n",
      "46/148 done\n",
      "47/148 done\n",
      "48/148 done\n",
      "49/148 done\n",
      "50/148 done\n",
      "51/148 done\n",
      "52/148 done\n",
      "53/148 done\n",
      "54/148 done\n",
      "55/148 done\n",
      "56/148 done\n",
      "57/148 done\n",
      "58/148 done\n",
      "59/148 done\n",
      "60/148 done\n",
      "61/148 done\n",
      "62/148 done\n",
      "63/148 done\n",
      "64/148 done\n",
      "65/148 done\n",
      "66/148 done\n",
      "67/148 done\n",
      "68/148 done\n",
      "69/148 done\n",
      "70/148 done\n",
      "71/148 done\n",
      "72/148 done\n",
      "73/148 done\n",
      "74/148 done\n",
      "75/148 done\n",
      "76/148 done\n",
      "77/148 done\n",
      "78/148 done\n",
      "79/148 done\n",
      "80/148 done\n",
      "81/148 done\n",
      "82/148 done\n",
      "83/148 done\n",
      "84/148 done\n",
      "85/148 done\n",
      "86/148 done\n",
      "87/148 done\n",
      "88/148 done\n",
      "89/148 done\n",
      "90/148 done\n",
      "91/148 done\n",
      "92/148 done\n",
      "93/148 done\n",
      "94/148 done\n",
      "95/148 done\n",
      "96/148 done\n",
      "97/148 done\n",
      "98/148 done\n",
      "99/148 done\n",
      "100/148 done\n",
      "101/148 done\n",
      "102/148 done\n",
      "103/148 done\n",
      "104/148 done\n",
      "105/148 done\n",
      "106/148 done\n",
      "107/148 done\n",
      "108/148 done\n",
      "109/148 done\n",
      "110/148 done\n",
      "111/148 done\n",
      "112/148 done\n",
      "113/148 done\n",
      "114/148 done\n",
      "115/148 done\n",
      "116/148 done\n",
      "117/148 done\n",
      "118/148 done\n",
      "119/148 done\n",
      "120/148 done\n",
      "121/148 done\n",
      "122/148 done\n",
      "123/148 done\n",
      "124/148 done\n",
      "125/148 done\n",
      "126/148 done\n",
      "127/148 done\n",
      "128/148 done\n",
      "129/148 done\n",
      "130/148 done\n",
      "131/148 done\n",
      "132/148 done\n",
      "133/148 done\n",
      "134/148 done\n",
      "135/148 done\n",
      "136/148 done\n",
      "137/148 done\n",
      "138/148 done\n",
      "139/148 done\n",
      "140/148 done\n",
      "141/148 done\n",
      "142/148 done\n",
      "143/148 done\n",
      "144/148 done\n",
      "145/148 done\n",
      "146/148 done\n",
      "147/148 done\n",
      "148/148 done\n",
      "23 inserts | 125 updates\n"
     ]
    }
   ],
   "source": [
    "columns = ['datetimeFirst', 'datetimeLast', 'url', 'title', 'salaryAndContract', 'salaryMin', 'salaryMax', 'employer', 'workModes', 'positionLevels', 'offerValidTo', 'location', 'techstackExpected', 'techstackOptional', 'responsibilities', 'requirements', 'optionalRequirements']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "timeDeltas = []\n",
    "inserts = 0\n",
    "updates = 0\n",
    "print(database.countAllRecords() + ' records before run')\n",
    "# for i in range (0,2):\n",
    "for i in range (len(offers_urls)):\n",
    "    driver.get(offers_urls[i])\n",
    "    if not offerNotFound():\n",
    "        resultsList = getOfferDetails()\n",
    "        outputDictionary = {}\n",
    "        for column, offerDetail in zip(columns, resultsList):\n",
    "            outputDictionary[column] = offerDetail #combine 2 lists into 1 dictionary\n",
    "        before = time.time()\n",
    "        if database.recordFound(driver.current_url):\n",
    "            database.updateDatetimeLast(driver.current_url)\n",
    "            # print(driver.current_url)\n",
    "            updates += 1\n",
    "        else:\n",
    "            database.insertRecord(outputDictionary) # insert into databas\n",
    "            inserts += 1\n",
    "            # print('insert')\n",
    "        timeDeltas.append(time.time() - before)\n",
    "        #ending here and starting in an above for/zip loop it takes ~(1/100)s - good enough\n",
    "        print (str(i+1) + '/' + str(len(offers_urls)) + ' done')\n",
    "    else:\n",
    "        print('OFFER NOT FOUND: ' +  driver.current_url)\n",
    "    time.sleep(random.uniform(0.35,0.85)) #Humanize requests frequency\n",
    "# print(np.mean(timeDeltas))\n",
    "print(str(inserts) + ' inserts | ' + str(updates) + ' updates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "## TODO: waluty -> zł? chyba nie ma innej waluty na stronie\n",
    "## elif group.text[0:8] == 'OPTIONAL': #never saw polish version yet\n",
    "# wykresy posortowane po salaryMin/Max\n",
    "# wykresy po zliczeniu słów?\n",
    "# możliwość łączenia filtrów i pokazywania wyników na wykresie posortowanych po x?\n",
    "# search or exclude by keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
