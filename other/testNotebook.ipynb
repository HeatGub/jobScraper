{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a browser and set the cookies from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'functionDone': True,\n",
       " 'message': 'cookies for justjoin.it successfully set'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True # recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "\n",
    "# ChromeDriver should match browser version. If outdated download from:\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "def setCookiesFromJson():  \n",
    "    try:\n",
    "        DRIVER.get(BASE_URL) #RUN BROWSER\n",
    "        currentUrlDomain = DRIVER.current_url\n",
    "        currentUrlDomain = re.search(r'^https?://([^/]+)', currentUrlDomain)\n",
    "        currentUrlDomain = currentUrlDomain.group(1)  \n",
    "        currentUrlDomain = re.sub(r'^www\\.', '', currentUrlDomain)\n",
    "        currentUrlDomain = re.sub(r'^\\.', '', currentUrlDomain)\n",
    "        # print(currentUrlDomain)\n",
    "        with open('cookies.json', 'r', newline='') as inputdata:\n",
    "            cookies = json.load(inputdata)\n",
    "            cookiesAdded = 0\n",
    "            for cookie in cookies: #works only after driver.get\n",
    "                if re.match(r\".?\"+currentUrlDomain, cookie['domain']): # can only add cookies for current domain\n",
    "                    DRIVER.add_cookie(cookie)\n",
    "                    cookiesAdded += 1\n",
    "            if cookiesAdded > 0:\n",
    "                DRIVER.refresh() # to load cookies\n",
    "                return {'success':True, 'functionDone':True, 'message':'cookies for ' + currentUrlDomain + ' successfully set'}\n",
    "            elif (cookiesAdded == 0):\n",
    "                return {'success':False, 'functionDone':True, 'message':'no cookies for ' + currentUrlDomain + ' found in cookies.json'}\n",
    "    except Exception as exception:\n",
    "        return {'success':False, 'functionDone':True, 'message':str(exception)} # 'functionDone':True because it's not necessary\n",
    "\n",
    "# service = Service(executable_path=\"chromedriver.exe\")\n",
    "service = Service(executable_path=r\"C:\\Users\\Ya\\Desktop\\Kody\\Phyhyton\\selenium\\chromedriver.exe\") # for some reason relative path in notebook doesn't work any more\n",
    "\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "chrome_options.add_argument(\"window-size=800,1000\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "DRIVER = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "BASE_URL = \"https://justjoin.it/job-offers/bialystok\"\n",
    "DRIVER.get(BASE_URL)\n",
    "setCookiesFromJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the URLs from all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetchAllOffersUrls while True:\n",
      "0\n",
      "24\n",
      "fetchAllOffersUrls while True:\n",
      "24\n",
      "24\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "24\n",
      "52\n",
      "fetchAllOffersUrls while True:\n",
      "52\n",
      "77\n",
      "fetchAllOffersUrls while True:\n",
      "77\n",
      "77\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "77\n",
      "83\n",
      "fetchAllOffersUrls while True:\n",
      "83\n",
      "83\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "83\n",
      "83\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "83\n",
      "83\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "83\n",
      "83\n",
      "noNewResults\n",
      "fetchAllOffersUrls while True:\n",
      "83\n",
      "83\n",
      "noNewResults\n",
      "RETURN\n",
      "first and last OFFERS_URLS:  0 96\n"
     ]
    }
   ],
   "source": [
    "# def getLastOfferIndex():\n",
    "#     try:\n",
    "#         DRIVER.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # scroll to the bottom\n",
    "#         offersList = DRIVER.find_element(By.ID, 'up-offers-list')\n",
    "#         offers = offersList.find_elements(By.XPATH, '//li[@data-index]') # amount depends on screen height \n",
    "#         lastIndex = offers[-1].get_attribute('data-index')\n",
    "#         return lastIndex\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return\n",
    "\n",
    "def offerNotFound():\n",
    "    try:\n",
    "        offerContent = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-tnvghs')\n",
    "        topContainer = offerContent.find_element(By.CSS_SELECTOR, 'div') # 1st div\n",
    "        # NEED TO FIND 'OFFER NOT FOUND MSG AND CHECK WHICH DIVS DOES IT HAVE\n",
    "        # topDiv = topContainer.find_element(By.XPATH, \".//*[contains(@class, 'css-10x887j')]\")\n",
    "        return False # if topDiv found, offer is there\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def anyOffersOnTheList():\n",
    "    try:\n",
    "        # offersList = DRIVER.find_element(By.ID, 'up-offers-list') # changed back to virtuoso ~15.01.2025 xD\n",
    "        # offers = offersList.find_elements(By.XPATH, '//li[@data-index]') # changed back to virtuoso ~15.01.2025 xD\n",
    "\n",
    "        offersList = DRIVER.find_element(By.XPATH, '//*[@data-test-id=\"virtuoso-item-list\"]') # changed to up-offers-list ~25.12.2024\n",
    "        offers = offersList.find_elements(By.XPATH, 'div[@data-index]') # virtuoso approach\n",
    "        # print(len(offers))\n",
    "        if len(offers) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return False\n",
    "\n",
    "OFFERS_URLS = []\n",
    "\n",
    "def fetchCurrentlyVisibleOffersUrls(): # just the ones currently rendered in browser\n",
    "    try:\n",
    "        offersList = DRIVER.find_element(By.XPATH, '//*[@data-test-id=\"virtuoso-item-list\"]') # changed to up-offers-list ~25.12.2024\n",
    "        offers = offersList.find_elements(By.XPATH, 'div[@data-index]') # amount depends on screen height \n",
    "        for offer in offers: # ever-loading div among them\n",
    "            try:\n",
    "                index = offer.get_attribute('data-index')\n",
    "                href = offer.find_element(By.XPATH, \".//div/div/a\").get_property(\"href\")\n",
    "\n",
    "                def foundAmongSavedIndexes():\n",
    "                    if len(OFFERS_URLS) == 0:\n",
    "                        return False # no offers\n",
    "                    for i in range (len(OFFERS_URLS[-30:])): # 30 last offers (or less if len < 30)\n",
    "                        if index == OFFERS_URLS[-i - 1]['index']: # decrementing from the end\n",
    "                            return True\n",
    "                    return False # not found if reached this return\n",
    "                \n",
    "                if not foundAmongSavedIndexes():\n",
    "                    OFFERS_URLS.append({'index':index, 'url':href})\n",
    "            \n",
    "            except:\n",
    "                pass #if url not found\n",
    "        # if len(OFFERS_URLS) >=1:\n",
    "        #     print(int(OFFERS_URLS[-1]['index']) - int(OFFERS_URLS[0]['index']) + 1, len(OFFERS_URLS))\n",
    "        #     print('first and last OFFERS_URLS: ', OFFERS_URLS[0]['index'], OFFERS_URLS[-1]['index'])\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        return\n",
    "\n",
    "def fetchAllOffersUrls():\n",
    "    noNewResultsCounter = 0\n",
    "    lastSeenIndex = 0\n",
    "    if not anyOffersOnTheList():\n",
    "        return\n",
    "    \n",
    "    DRIVER.execute_script(\"window.scrollTo(0, 0);\") # scroll to the top\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    while True: # endless loop only ending at return\n",
    "        print('fetchAllOffersUrls while True:')\n",
    "        print(len(OFFERS_URLS))\n",
    "        fetchCurrentlyVisibleOffersUrls() # updates OFFERS_URLS\n",
    "        print(len(OFFERS_URLS))\n",
    "\n",
    "        if len(OFFERS_URLS) == 0: # should have results already from the above function execution\n",
    "            noNewResultsCounter += 1\n",
    "        elif len(OFFERS_URLS) > 0:\n",
    "            # no new offer index found\n",
    "            if (lastSeenIndex == OFFERS_URLS[-1]['index']):\n",
    "                noNewResultsCounter += 1\n",
    "                DRIVER.execute_script(\"window.scrollBy(0, -2*innerHeight);\") # for some reason scrolling up helps this fucking site to load the bottom\n",
    "                time.sleep(1)\n",
    "                DRIVER.execute_script(\"window.scrollBy(0, 3*innerHeight);\") # scroll to the bottom\n",
    "                print('noNewResults')\n",
    "                # print(OFFERS_URLS[0]['index'], OFFERS_URLS[-1]['index'])\n",
    "            # if new offer index found reset the counter\n",
    "            else: \n",
    "                noNewResultsCounter = 0\n",
    "\n",
    "        # CHECK IF READY TO TERMINATE\n",
    "        if noNewResultsCounter >= 5: # or int(lastSeenIndex) >= 10: # END IF NO NEW RESULTS FEW TIMES\n",
    "            print('RETURN')\n",
    "            #print(int(OFFERS_URLS[-1]['index']) - int(OFFERS_URLS[0]['index']) + 1, len(OFFERS_URLS))\n",
    "            print('first and last OFFERS_URLS: ', OFFERS_URLS[0]['index'], OFFERS_URLS[-1]['index'])\n",
    "            return\n",
    "        \n",
    "        #UPDATE LAST INDEX\n",
    "        lastSeenIndex = OFFERS_URLS[-1]['index']\n",
    "        time.sleep(0.5)\n",
    "        DRIVER.execute_script(\"window.scrollBy(0, innerHeight);\")\n",
    "\n",
    "fetchAllOffersUrls()\n",
    "# fetchCurrentlyVisibleOffersUrls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse offer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "120 - 140 PLN/h\n",
      "Net per hour - B2B\n",
      "\n",
      "120 - 140 PLN/h Net per hour - B2B\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'datetimeLast': '2025-04-02 16:55:11',\n",
       " 'datetimeFirst': '2025-04-02 16:55:11',\n",
       " 'url': 'https://justjoin.it/job-offer/itlt-senior-tech-lead-python-developer-warszawa-python',\n",
       " 'title': '',\n",
       " 'salaryAndContract': '120 - 140 PLN/h\\nNet per hour - B2B\\nFull-time | B2B',\n",
       " 'salaryMin': 20160,\n",
       " 'salaryMax': 23520,\n",
       " 'employer': '',\n",
       " 'workModes': 'Remote',\n",
       " 'positionLevels': 'Senior',\n",
       " 'location': 'Warszawa',\n",
       " 'techstackExpected': 'Django - Advanced\\nPython - Advanced\\nGit - Regular\\nWebSocket - Regular\\nDocker - Regular\\nKubernetes - Regular',\n",
       " 'techstackOptional': '',\n",
       " 'responsibilities': 'Twoje zadania:Projektowanie architektury i implementacja rozwiązań, w tym aktywny wkład w kodowanie\\nIntegracja platformy z innymi systemamiTworzenie architektury i zapewnianie jakości oraz spójności projektuWspółpraca z zespołem, klientem i Project Managerem',\n",
       " 'requirements': 'Przekładanie potrzeb biznesowych na rozwiązania techniczne oraz komunikacja z klientemOczekiwania:\\nMin. 6 lat doświadczenia z Python/Django\\nBardzo dobra znajomość WebSockets i FastAPI\\nDoświadczenie w integracjach systemów\\nDoświadczenie w roli lidera i komunikacji z klientem\\nPodstawowa znajomość .NET oraz ChatGPT',\n",
       " 'optionalRequirements': 'Mile widziana znajomość:\\nAzure\\nCI/CD\\nFrontend\\nOferujemy:\\nDługofalowe stabilne zatrudnienie w oparciu o kontrakt B2B\\nSzansa na rozwój w dużej strukturze, bezpośredni kontakt z Managerem zespołu\\nPraca w firmie, w której IT jest dojrzałe i globalne, a metodyki zwinne są respektowane\\nDopłata do karty MultiSport oraz ubezpieczenia',\n",
       " 'fullDescription': 'Ogólne informacje:\\nZatrudnienie: kontrakt b2b, pełny wymiar godzin - współpraca długofalowa\\nStawka: 120 - 140 PLN netto + Vat/h\\nStart: ASAP (ważne!)\\nLokalizacja biura: Warszawa\\nTryb pracy: praca zdalna + sporadyczne wizyty w biurze (1 x miesiąc)\\nSektor: technologie IT / sztuczna inteligencja\\nStack technologiczny: Django, Django REST framework, Docker, Kubernetes, bazy danych SQL i NoSQL, AWS, Websockets, Git\\n Twoje zadania:\\nProjektowanie architektury i implementacja rozwiązań, w tym aktywny wkład w kodowanie\\nIntegracja platformy z innymi systemami\\nPrzekładanie potrzeb biznesowych na rozwiązania techniczne oraz komunikacja z klientem\\nTworzenie architektury i zapewnianie jakości oraz spójności projektu\\nWspółpraca z zespołem, klientem i Project Managerem\\nOczekiwania:\\nMin. 6 lat doświadczenia z Python/Django\\nBardzo dobra znajomość WebSockets i FastAPI\\nDoświadczenie w integracjach systemów\\nDoświadczenie w roli lidera i komunikacji z klientem\\nPodstawowa znajomość .NET oraz ChatGPT\\nMile widziana znajomość:\\nAzure\\nCI/CD\\nFrontend\\nOferujemy:\\nDługofalowe stabilne zatrudnienie w oparciu o kontrakt B2B\\nSzansa na rozwój w dużej strukturze, bezpośredni kontakt z Managerem zespołu\\nPraca w firmie, w której IT jest dojrzałe i globalne, a metodyki zwinne są respektowane\\nDopłata do karty MultiSport oraz ubezpieczenia'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getOfferDetails():\n",
    "    # BASIC PARAMETERS WHICH SHOULD ALWAYS BE NOT EMPTY ON THE SITE\n",
    "    try:\n",
    "        offerContent = DRIVER.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-tnvghs')\n",
    "        topContainer = offerContent.find_element(By.CSS_SELECTOR, 'div')\n",
    "        topDiv = topContainer.find_element(By.XPATH, \".//*[contains(@class, 'css-10x887j')]\") # .// = as deep as necessary\n",
    "    except Exception as exception:\n",
    "        # print(exception)\n",
    "        return # no point of continuing\n",
    "    try:\n",
    "        jobTitle = topDiv.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "        # print(jobTitle)\n",
    "        employerAndLocationDiv = topDiv.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-yd5zxy') \n",
    "        employer = employerAndLocationDiv.find_element(By.XPATH, './/h2').text # look for h2 as deep as necessary\n",
    "        # print(employer) # name=\"multilocation_button\"\n",
    "    except:\n",
    "        jobTitle, employer = '', ''\n",
    "\n",
    "    try:\n",
    "        location = employerAndLocationDiv.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-mswf74')[1].text # first one is employer\n",
    "        location = re.sub(r'\\+[0-9]+$', '', location) #remove '+x' where x is int\n",
    "    except:\n",
    "        location = ''\n",
    "    #try clicking for more locations\n",
    "    try:\n",
    "        locationButton = employerAndLocationDiv.find_element(\"xpath\", '//*[@name=\"multilocation_button\"]')\n",
    "        locationButton.click()\n",
    "        locationsMenu = offerContent.find_element(\"xpath\", '//ul[@role=\"menu\"]')\n",
    "        # locationsMenu = locationsMenu.find_elements(By.CSS_SELECTOR, 'li')\n",
    "        location += '\\n' + locationsMenu.text # TEXT EMPTY WHEN MINIMIZED!\n",
    "    except Exception as exception:\n",
    "        pass\n",
    "    # print(location)\n",
    "\n",
    "    #SALARY\n",
    "    try:\n",
    "        salaryAndContract = topContainer.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-1km0bek').text\n",
    "    except:\n",
    "        salaryAndContract= ''\n",
    "\n",
    "    salaryMinAndMax = [None, None] # Nones as these are INTs in DB\n",
    "    if salaryAndContract != '':\n",
    "        try: #to recalculate salary to [PLN/month net]\n",
    "            grossToNetMultiplier = 0.7\n",
    "            hoursPerMonthInFullTimeJob = 168\n",
    "            minAndMaxLine = salaryAndContract.splitlines()[0] # There could be multiple salaries depending on contract type though. It will be in salaryAndContract anyway\n",
    "            secondLine = salaryAndContract.splitlines()[1]\n",
    "            splitValues = re.split(r'-', minAndMaxLine) # split on dash for min and max\n",
    "\n",
    "            for i in range(len(splitValues)):\n",
    "                splitValues[i] = splitValues[i].replace(\" \", \"\") # remove spaces\n",
    "                splitValues[i] = re.sub(r\",\\d{1,2}\", '', splitValues[i]) # removes , and /d{1 to 2 occurrences}  (needed when salary as 123,45)\n",
    "                salaryMinAndMax[i] = re.search(r\"\\d+\", splitValues[i]).group() # r = raw, \\d+ = at least 1 digit, group() contains results\n",
    "\n",
    "            if re.findall(\"brutto\", secondLine) or re.findall(\"gross\", secondLine): # gross -> net\n",
    "                salaryMinAndMax = [(float(elmnt) * grossToNetMultiplier) for elmnt in salaryMinAndMax]\n",
    "                # print(salaryMinAndMax)\n",
    "            if re.findall(\"hour\", secondLine) or re.findall(r\"/h\", secondLine) or re.findall(\"godz\", secondLine): # hr -> month\n",
    "                salaryMinAndMax = [(float(elmnt) * hoursPerMonthInFullTimeJob) for elmnt in salaryMinAndMax] #possible input float/str\n",
    "\n",
    "            salaryMinAndMax = [int(elmnt) for elmnt in salaryMinAndMax] # to ints\n",
    "        except Exception as exception:\n",
    "            pass    # salaryMinAndMax = [None, None]\n",
    "    # print(salaryMinAndMax)\n",
    "\n",
    "    # print(salaryAndContract)\n",
    "    workModes = ''\n",
    "    positionLevels = ''\n",
    "\n",
    "    try:\n",
    "        # MuiBox-root css-ktfb40\n",
    "        fourRectanglesContainer = offerContent.find_elements(By.XPATH, \"./div\")[1] # only child divs, not grandchild or further - 1 level down\n",
    "        # print(fourRectanglesContainer.text)\n",
    "        fourRectangles = fourRectanglesContainer.find_elements(By.XPATH, \"./div\")\n",
    "\n",
    "        for i in range(len(fourRectangles)):\n",
    "            fourRectangles[i] = fourRectangles[i].find_elements(By.XPATH, \"./div\")[1] # second child div (not grandchild or further)\n",
    "            fourRectangles[i] = fourRectangles[i].find_elements(By.XPATH, \"./div\")[1].text\n",
    "            # print(fourRectangles[i])\n",
    "        salaryAndContract += '\\n' + fourRectangles[0] + ' | ' + fourRectangles[2]\n",
    "        positionLevels = fourRectangles[1]\n",
    "        workModes = fourRectangles[3]\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass\n",
    "    # print(salaryAndContract)\n",
    "    # print(workModes, positionLevels + '\\n')\n",
    "\n",
    "    #TECHSTACK\n",
    "    techstackExpected, techstackOptional = '', ''\n",
    "    try:\n",
    "        # techstackDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[0] # changed 04.2025\n",
    "        # techstackDiv = techstackDiv.find_element(By.CSS_SELECTOR, 'div')\n",
    "        techstackDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiStack-root.css-6r2fzw')[0]\n",
    "\n",
    "        technologies = techstackDiv.find_elements(By.XPATH, './/h4') # look for h4 in all children elements\n",
    "        levels = techstackDiv.find_elements(By.XPATH, './/span') # look for h4 in all children elements\n",
    "        for i in range(len(technologies)):\n",
    "            techWithLvl = technologies[i].text + ' - ' + levels[i].text\n",
    "            # print(techWithLvl)\n",
    "            if levels[i].text == 'Nice To Have': # or levels[i].text == 'Junior'\n",
    "                techstackOptional += '\\n' + techWithLvl\n",
    "            else: # -(nice to have)/junior/regular/advanced/master\n",
    "                techstackExpected += '\\n' + techWithLvl\n",
    "\n",
    "        techstackOptional = re.sub(r\"^\\n\", '', techstackOptional)\n",
    "        techstackExpected = re.sub(r\"^\\n\", '', techstackExpected)\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass # leave empty strs\n",
    "    # print(techstackExpected + '\\n\\n' + techstackOptional)\n",
    "\n",
    "    offerValidTo = '' # REMOVE FROM DB?\n",
    "    fullDescription = '' # ADD TO DB\n",
    "    responsibilities, requirements, optionalRequirements, theyOffer = '', '', '', ''\n",
    "\n",
    "    optionalRequirementsKeywords = ['nice to', 'optional', 'ideal', 'prefer', 'asset', 'appreciat', 'atut', 'dodatk', 'mile widzi']\n",
    "    requirementsKeywords = ['require', 'expect', 'skill', 'look', 'qualifications', 'must', 'competen', 'wymaga', 'oczek', 'umiejętn', 'aplikuj, jeśli', 'oczekuj', 'potrzeb', 'szukamy', 'kompeten']\n",
    "    responsibilitiesKeywords = ['responsib', 'task', 'role', 'project', 'obowiązk', 'zadani', 'projek']\n",
    "    whatTheyOfferKeywords = ['offer', 'benefit' 'oferuj', 'oferow']\n",
    "\n",
    "    allKeywordsDict = {'optionalRequirementsKeywords':optionalRequirementsKeywords, 'requirementsKeywords':requirementsKeywords, 'responsibilitiesKeywords':responsibilitiesKeywords}\n",
    "\n",
    "    try:\n",
    "        # descriptionDiv = offerContent.find_elements(By.CSS_SELECTOR, '.MuiBox-root.css-qal8sw')[1] # changed 31.03.20205 (not sure when on jj.it)\n",
    "        # descriptionDiv = descriptionDiv.find_elements(By.XPATH, \"./div\")[1] # second child div\n",
    "        descriptionDiv = offerContent.find_element(By.CSS_SELECTOR, '.MuiBox-root.css-rcazos')\n",
    "        \n",
    "        # Remove empty lines (including those with spaces)\n",
    "        fullDescription = re.sub(r'^\\s*\\n', '', descriptionDiv.text, flags=re.MULTILINE)\n",
    "        # print(fullDescription)\n",
    "\n",
    "        def splitTextByKeywords(text, keywords):\n",
    "            lines = text.split(\"\\n\")  # Split text into lines\n",
    "            keywordIndices = [i for i, line in enumerate(lines) if any(keyword.lower() in line.lower() for keyword in keywords)]\n",
    "            # If no keywords found, return the original text as one paragraph\n",
    "            if not keywordIndices:\n",
    "                return [text]\n",
    "            \n",
    "            paragraphs = []\n",
    "            startIndex = 0\n",
    "            for keywordIndex in keywordIndices:\n",
    "                # if startIndex != keywordIndex:\n",
    "                paragraphs.append(\"\\n\".join(lines[startIndex:keywordIndex]).strip())  # Capture paragraph before keyword\n",
    "                startIndex = keywordIndex  # Update start for next section\n",
    "            paragraphs.append(\"\\n\".join(lines[startIndex:]).strip())  # Capture the last paragraph\n",
    "            return paragraphs\n",
    "        \n",
    "        keywords = optionalRequirementsKeywords + requirementsKeywords + responsibilitiesKeywords + whatTheyOfferKeywords # just concat keywords lists as they will be assigned to a category later\n",
    "        paragraphs = splitTextByKeywords(fullDescription, keywords)\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            if not paragraph or re.search(r\"^\\s*$\", paragraph): # \\s matches Unicode whitespace characters. This includes [ \\t\\n\\r\\f\\v] and more\n",
    "                continue # don't try to analyze an empty sting, go with next loop iteration\n",
    "            # look for keywords in the 1st line of text\n",
    "            header = paragraph.splitlines()[0] # first line\n",
    "            # print('=====================')\n",
    "            # print(header)\n",
    "            # print(paragraph)\n",
    "            for keywordsCategory in allKeywordsDict.keys():\n",
    "                # print(keywordsCategory)\n",
    "                for keyword in allKeywordsDict[keywordsCategory]:\n",
    "                    # if keyword found in header\n",
    "                    # if re.search(rf'\\b{re.escape(keyword)}\\b', header, re.IGNORECASE): # \\b = boundaries - matches whole words, regardless of punctuation or position in the string # escapes = escape regex reserved symbols\n",
    "                    if re.search(rf'.*{re.escape(keyword)}.*', header, re.IGNORECASE): # .* = any symbol any number of times\n",
    "                        # print('found ' + keyword)\n",
    "                        if keywordsCategory =='optionalRequirementsKeywords': # check this first as it's more specific than requirements and contains similar keywords\n",
    "                            optionalRequirements += paragraph\n",
    "                        elif keywordsCategory =='requirementsKeywords':\n",
    "                            requirements += paragraph\n",
    "                        elif keywordsCategory =='responsibilitiesKeywords':\n",
    "                            responsibilities += paragraph\n",
    "                        elif keywordsCategory == 'whatTheyOfferKeywords':\n",
    "                            whatTheyOfferKeywords += paragraph\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "        pass\n",
    "\n",
    "    # print('\\n\\n'+ responsibilities +'\\n\\n'+ requirements +'\\n\\n'+ optionalRequirements)\n",
    "    datetimeNow = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return {'datetimeLast':datetimeNow, 'datetimeFirst':datetimeNow, 'url':DRIVER.current_url, 'title':jobTitle, 'salaryAndContract':salaryAndContract, 'salaryMin':salaryMinAndMax[0], 'salaryMax':salaryMinAndMax[1], 'employer':employer, 'workModes':workModes, 'positionLevels':positionLevels, 'location':location, 'techstackExpected':techstackExpected, 'techstackOptional':techstackOptional, 'responsibilities':responsibilities, 'requirements':requirements, 'optionalRequirements':optionalRequirements, 'fullDescription':fullDescription}\n",
    "\n",
    "# testing below\n",
    "DRIVER.get('https://justjoin.it/job-offer/itlt-senior-tech-lead-python-developer-warszawa-python')\n",
    "# DRIVER.switch_to.window(DRIVER.window_handles[-1])\n",
    "getOfferDetails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databaseFunctions import Database\n",
    "from settings import DATABASE_COLUMNS\n",
    "# import numpy as np\n",
    "\n",
    "def scrapToDatabase():\n",
    "    # timeDeltas = []\n",
    "    inserts = 0\n",
    "    updates = 0\n",
    "    print(Database.countAllRecords() + ' records before run')\n",
    "    # for i in range (0,2):\n",
    "    for i in range (len(OFFERS_URLS)):\n",
    "        DRIVER.get(OFFERS_URLS[i]['url'])\n",
    "        if not offerNotFound():\n",
    "            # LOOK FOR COMMON KEYS AS getOfferDetails() can return more keys than custom shortened DB has columns\n",
    "            offerDetailsDict = getOfferDetails()\n",
    "            # a dictionary containing only the keys appearing in both dictionaries\n",
    "            commonKeysDict = {key: offerDetailsDict[key] for key in DATABASE_COLUMNS if key in offerDetailsDict}\n",
    "            \n",
    "            # # before = time.time()\n",
    "            if Database.recordFound(DRIVER.current_url):\n",
    "                Database.updateDatetimeLast(DRIVER.current_url)\n",
    "                # print(driver.current_url)\n",
    "                updates += 1\n",
    "            else:\n",
    "                Database.insertRecord(commonKeysDict) # insert into database\n",
    "                inserts += 1\n",
    "                # print('insert')\n",
    "            # timeDeltas.append(time.time() - before)\n",
    "            #ending here and starting in an above for/zip loop it takes ~(1/100)s - good enough\n",
    "            print (str(i+1) + '/' + str(len(OFFERS_URLS)) + ' done')\n",
    "        else:\n",
    "            print('OFFER NOT FOUND: ' +  DRIVER.current_url)\n",
    "        # time.sleep(random.uniform(0.35,0.85)) # Humanize requests frequency - justjoin slow already\n",
    "    # print(np.mean(timeDeltas))\n",
    "    print(str(inserts) + ' inserts | ' + str(updates) + ' updates')\n",
    "\n",
    "scrapToDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,json, random, re, datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True # recommended - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "\n",
    "# ChromeDriver should match browser version. If outdated download from:\n",
    "# https://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "def setCookiesFromJson():  \n",
    "    try:\n",
    "        DRIVER.get(BASE_URL) #RUN BROWSER\n",
    "        currentUrlDomain = DRIVER.current_url\n",
    "        currentUrlDomain = re.search(r'^https?://([^/]+)', currentUrlDomain)\n",
    "        currentUrlDomain = currentUrlDomain.group(1)  \n",
    "        currentUrlDomain = re.sub(r'^www\\.', '', currentUrlDomain)\n",
    "        currentUrlDomain = re.sub(r'^\\.', '', currentUrlDomain)\n",
    "        # print(currentUrlDomain)\n",
    "        with open('cookies.json', 'r', newline='') as inputdata:\n",
    "            cookies = json.load(inputdata)\n",
    "            cookiesAdded = 0\n",
    "            for cookie in cookies: #works only after driver.get\n",
    "                if re.match(r\".?\"+currentUrlDomain, cookie['domain']): # can only add cookies for current domain\n",
    "                    DRIVER.add_cookie(cookie)\n",
    "                    cookiesAdded += 1\n",
    "            if cookiesAdded > 0:\n",
    "                DRIVER.refresh() # to load cookies\n",
    "                return {'success':True, 'functionDone':True, 'message':'cookies for ' + currentUrlDomain + ' successfully set'}\n",
    "            elif (cookiesAdded == 0):\n",
    "                return {'success':False, 'functionDone':True, 'message':'no cookies for ' + currentUrlDomain + ' found in cookies.json'}\n",
    "    except Exception as exception:\n",
    "        return {'success':False, 'functionDone':True, 'message':str(exception)} # 'functionDone':True because it's not necessary\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "chrome_options.add_argument(\"window-size=800,1000\")\n",
    "# chrome_options.add_experimental_option('excludeSwitches', ['enable-logging']) #disable error logging\n",
    "BASE_URL = \"https://justjoin.it/job-offer/relativity-senior-software-engin\"\n",
    "\n",
    "# DRIVER = webdriver.Chrome(service=service, options=chrome_options)\n",
    "# DRIVER.get(BASE_URL)\n",
    "# setCookiesFromJson()\n",
    "\n",
    "# Find elements containing specific text\n",
    "\n",
    "def offerNotFound():\n",
    "    try:\n",
    "        # Sorry, we cannot display this page. It is possible that its address has changed or it has been removed.\n",
    "        notFoundMsg = 'we cannot display this page'\n",
    "        notFoundMsgDivs = DRIVER.find_elements(By.CLASS_NAME, \"css-czlivx\") # only 1 element of that class found tho\n",
    "        for div in notFoundMsgDivs:\n",
    "            # Case-insensitive check\n",
    "            if notFoundMsg.lower() in div.text.lower():\n",
    "                print(div.text)\n",
    "                return True\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "offerNotFound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "# Data source\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=[1, 2, 3, 4, 5],\n",
    "    y=[6, 7, 2, 4, 5],\n",
    "    color=[\"red\", \"green\", \"blue\", \"orange\", \"purple\"]\n",
    "))\n",
    "\n",
    "# Create a figure\n",
    "p = figure(title=\"Bokeh Plot with Selection Color\", tools=\"tap\")\n",
    "\n",
    "# Add a circle glyph with selection and nonselection colors\n",
    "renderer = p.circle(\n",
    "    x='x', y='y', size=20, color='color', source=source,\n",
    "    selection_color=\"gold\",  # Color of selected items\n",
    "    nonselection_fill_color=\"gray\",  # Color of non-selected items\n",
    "    nonselection_fill_alpha=0.2  # Transparency of non-selected items\n",
    ")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1:\n",
      "Company: ABC Corp\n",
      "We are hiring a software engineer.\n",
      "----------------------------------------\n",
      "Paragraph 2:\n",
      "Responsibilities:\n",
      "- Develop applications\n",
      "- Fix bugs\n",
      "----------------------------------------\n",
      "Paragraph 3:\n",
      "Requirements:\n",
      "- Proficiency in Python\n",
      "----------------------------------------\n",
      "Paragraph 4:\n",
      "- Experience with Django\n",
      "\n",
      "Benefits:\n",
      "- Health insurance\n",
      "- Flexible hours\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def splitTextByKeywords(text, keywords):\n",
    "    lines = text.split(\"\\n\")  # Split text into lines\n",
    "    keywordIndices = [i for i, line in enumerate(lines) if any(keyword.lower() in line.lower() for keyword in keywords)]\n",
    "\n",
    "    # If no keywords found, return the original text as one paragraph\n",
    "    if not keywordIndices:\n",
    "        return [text]\n",
    "    \n",
    "    paragraphs = []\n",
    "    startIndex = 0\n",
    "    for keywordIndex in keywordIndices:\n",
    "        # if startIndex != keywordIndex:\n",
    "        paragraphs.append(\"\\n\".join(lines[startIndex:keywordIndex]).strip())  # Capture paragraph before keyword\n",
    "        startIndex = keywordIndex  # Update start for next section\n",
    "    paragraphs.append(\"\\n\".join(lines[startIndex:]).strip())  # Capture the last paragraph\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "# Example Usage\n",
    "text = \"\"\"Company: ABC Corp\n",
    "We are hiring a software engineer.\n",
    "\n",
    "Responsibilities:\n",
    "- Develop applications\n",
    "- Fix bugs\n",
    "\n",
    "Requirements:\n",
    "- Proficiency in Python\n",
    "- Experience with Django\n",
    "\n",
    "Benefits:\n",
    "- Health insurance\n",
    "- Flexible hours\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# text = \"\"\"\n",
    "# \"\"\"\n",
    "\n",
    "# keywords = [\"Responsibilities\", \"Requirements\", \"Benefits\"]\n",
    "\n",
    "optionalRequirementsKeywords = ['nice to', 'optional', 'ideal', 'prefer', 'asset', 'appreciat', 'atut', 'dodatk', 'mile widzi']\n",
    "requirementsKeywords = ['require', 'expect', 'skill', 'look', 'qualifications', 'experience', 'must', 'competen', 'wymaga', 'oczek', 'umiejętn', 'aplikuj, jeśli', 'potrzeb', 'szukamy', 'kompeten']\n",
    "responsibilitiesKeywords = ['responsib', 'task', 'role', 'project', 'obowiązk', 'zadani', 'projek']\n",
    "whatTheyOfferKeywords = ['offer', 'benefit' 'oferuj', 'oferow']\n",
    "\n",
    "keywords = optionalRequirementsKeywords + requirementsKeywords + responsibilitiesKeywords + whatTheyOfferKeywords # just concat lists\n",
    "\n",
    "paragraphs = splitTextByKeywords(text, keywords)\n",
    "\n",
    "for i, para in enumerate(paragraphs):\n",
    "    print(f\"Paragraph {i+1}:\\n{para}\\n{'-'*40}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
